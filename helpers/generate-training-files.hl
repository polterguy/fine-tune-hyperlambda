
/*
 * Creates JSONL training data for all data we've got in our database
 * 
 * You have to manually download the data after generating it.
 *
 * This Hyperlambda connects to your fine-tune database, selects all rows from
 * 'hyperlambda' table, and creates a JSONL file intended for fine tuning OpenAI's models.
 *
 * In addition it inserts a system message which is loaded from disc, and a cheat-sheet it
 * also uses as training material. The code will create two files, one for training data and
 * another for validation data.
 */

// Buffer for snippets.
.result:

// Loading up system message
.system-message
set-value:x:-
   strings.concat
      io.file.load:/modules/fine-tune-hyperlambda/system-message.md
      .:"\n"

// Retrieving all training snippets.
data.connect:fine-tune
   data.select:select * from hyperlambda where validation = 0 order by mod(length(prompt), 11)

   // Iterating through snippets to generate training data.
   for-each:x:@data.select/*

      // Generating training record, starting with prompt.
      .prompt
      set-value:x:@.prompt
         get-value:x:@.dp/#/*/prompt

      // Then completion.
      .completion
      set-value:x:@.completion
         strings.concat
            get-value:x:@.dp/#/*/code
            .:"\n"

      // Creating our buffer object to hold our messages.
      unwrap:x:+/**
      .data
         messages
            .
               role:system
               content:x:@.system-message
            .
               role:user
               content:x:@.prompt
            .
               role:assistant
               content:x:@.completion

      // Adding training data to above [.result].
      set-value:x:@.result
         strings.concat
            get-value:x:@.result
            lambda2json:x:@.data/*
            .:"\n"

// Saving files.
io.file.save:/modules/fine-tune-hyperlambda/training-material.jsonl
   get-value:x:@.result

// Buffer for validation data.
.validation:

// Loading up system message
.system-message
set-value:x:-
   io.file.load:/modules/fine-tune-hyperlambda/system-message-validation.md

   // Retrieving all training snippets.
data.connect:fine-tune
   data.select:select * from hyperlambda where validation = 1 order by mod(length(prompt), 11)

   // Iterating through snippets to generate training data.
   for-each:x:@data.select/*

      // Generating training record, starting with prompt.
      .prompt
      set-value:x:@.prompt
         get-value:x:@.dp/#/*/prompt

      // Then completion.
      .completion
      set-value:x:@.completion
         get-value:x:@.dp/#/*/code

      // Creating our buffer object to hold our messages.
      unwrap:x:+/**
      .data
         messages
            .
               role:system
               content:x:@.system-message
            .
               role:user
               content:x:@.prompt
            .
               role:assistant
               content:x:@.completion

      // Adding training data to above [.result].
      set-value:x:@.validation
         strings.concat
            get-value:x:@.validation
            lambda2json:x:@.data/*
            .:"\n"

// Saving files.
io.file.save:/modules/fine-tune-hyperlambda/validation-material.jsonl
   get-value:x:@.validation

// Returning result to caller.
return
   training_file:/modules/fine-tune/training-material.jsonl
   validation_file:/modules/fine-tune/validation-material.jsonl
