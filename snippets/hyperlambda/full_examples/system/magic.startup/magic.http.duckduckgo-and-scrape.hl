
/*
 * Performs a DuckDuckGo search, scrapes the top N result URLs, and returns the content as aggregated Markdown.
 *
 * This dynamic slot, `magic.http.duckduckgo-and-scrape`, takes a search query and scrapes up to [max] URLs returned
 * from DuckDuckGo, aggregating the resulting semantic snippets into a structured Markdown-like format.
 * It executes all scraping operations in parallel using [fork]/[join] for efficiency, and optionally emits real-time
 * progress updates via WebSockets if a session ID is provided.
 *
 * ### Arguments:
 * - `query` (string, required): The search string to pass into DuckDuckGo. Must be between 3–250 characters.
 * - `max` (int, required): Maximum number of result URLs to scrape. Must be between 1–10.
 * - `session` (string, optional): A WebSocket session ID for emitting real-time scraping status updates.
 *
 * ### Behavior:
 * 1. **Validation**:
 *    - Ensures that `query` and `max` are present and valid.
 * 2. **Search**:
 *    - Uses [signal:magic.http.duckduckgo-search] to fetch search results from DuckDuckGo.
 *    - Extracts up to [max] URLs from the search result.
 * 3. **WebSocket Progress Notifications**:
 *    - If `session` is provided, emits messages as each URL begins scraping.
 * 4. **Parallel Scraping**:
 *    - Constructs a dynamic [fork]/[join] parallel execution tree.
 *    - Each forked thread calls [signal:magic.http.scrape-url] with `semantics: true`.
 *    - Scraped data includes semantic sections (prompt + completion format).
 *    - If scraping fails, logs the error silently and continues.
 * 5. **Aggregation**:
 *    - After all scrapers complete, the slot assembles the results:
 *      - Only includes entries where both `prompt` and `completion` exist.
 *      - Returns a list of results containing:
 *        - `url`: The original source URL.
 *        - `title`: The page title.
 *        - `snippets`: An array of semantic segments extracted from the page.
 * 6. **Final Output**:
 *    - A structured JSON array of enriched web snippets from the top search results.
 *
 * ### Returns:
 * A list of scraped results with semantic structure:
 * ```json
 * [
 *   {
 *     "url": "https://example.com/what-is-ai",
 *     "title": "What is Artificial Intelligence?",
 *     "snippets": [
 *       {
 *         "prompt": "Definition of AI",
 *         "completion": "Artificial Intelligence refers to machines that mimic human intelligence..."
 *       },
 *       ...
 *     ]
 *   },
 *   ...
 * ]
 * ```
 *
 * ### Notes:
 * - WebSocket progress signals can be used to inform users of scraping progress in real time.
 * - This slot is ideal for research tools, automated knowledge harvesting, summarization systems, or building LLM pretraining datasets.
 * - Scraping is subject to network delays and page variability; poorly structured or dynamic pages may return no usable content.
 */
slots.create:magic.http.duckduckgo-and-scrape

   // Sanity checking invocation.
   validators.mandatory:x:@.arguments/*/query
   validators.string:x:@.arguments/*/query
      min:3
      max:250
   validators.integer:x:@.arguments/*/max
      min:1
      max:10

   // Searching DuckDuckGo for matches.
   add:x:+
      get-nodes:x:@.arguments/*
   signal:magic.http.duckduckgo-search

   // Checking if we've got a session, and if so, notifying user using web sockets.
   if
      exists:x:@.arguments/*/session
      .lambda
         for-each:x:@signal/*/result/*
            strings.concat
               .:"Scraping: "
               get-value:x:@.dp/#/*/url
            unwrap:x:+/**
            sockets.signal:x:@.arguments/*/session
               args
                  message:x:@strings.concat
                  type:system
            sleep:100

   // Building our execution object that fetches all URLs simultaneously in parallel.
   .exe

      // Waiting for all scraping operations to return.
      join

   for-each:x:@signal/*/result/*

      // Dynamically contructing our lambda object.
      .cur
         fork
            .reference
            try
               unwrap:x:+/*
               signal:magic.http.scrape-url
                  url:x:@.reference/*/url
                  semantics:bool:true
               if
                  exists:x:@.reference/*/session
                  .lambda
                     strings.concat
                        .:"Done scraping "
                        get-value:x:@.reference/*/url
                     unwrap:x:+/**
                     sockets.signal:x:@.reference/*/session
                        args
                           message:x:@strings.concat
                           type:system
            .catch
               log.error:Could not scrape URL
                  url:x:@.reference/*/url
                  message:x:@.arguments/*/message

      // Adding URL and title as reference to currently iterated [fork].
      add:x:+/+/*
         get-nodes:x:@.arguments/*/session
      unwrap:x:+/*/*
      add:x:@.cur/*/fork/*/.reference
         .
            url:x:@.dp/#/*/url
            title:x:@.dp/#/*/title

      // Adding current thread to above [join].
      add:x:@.exe/*/join
         get-nodes:x:@.cur/*

   // Executing [.exe] retrieving all URLs in parallel.
   eval:x:@.exe
   remove-nodes:x:@.exe/**/session
   
   // Signaling caller on sockets.
   if
      exists:x:@.arguments/*/session
      .lambda
         sockets.signal:x:@.arguments/*/session
            args
               message:Building context
               type:system
         sleep:100

   /*
    * Iterating through each above result,
    * returning result to caller.
    *
    * Notice, we only iterate through invocations that have result, and
    * did not timeout by verifying [signal] slot has children.
    */
   for-each:x:@.exe/*/join/*/fork

      // Verifying currently iterated node has result, containing both prompt and completion.
      if
         exists:x:@.dp/#/*/try/*/signal/*/*/prompt/./*/completion
         .lambda

            // Adding primary return lambda to [return] below.
            unwrap:x:+/*/*/*
            add:x:../*/return
               .
                  .
                     url:x:@.dp/#/*/.reference/*/url
                     title:x:@.dp/#/*/.reference/*/title
                     snippets

            // Adding [snippets] to return below.
            add:x:../*/return/0/-/*/snippets
               get-nodes:x:@.dp/#/*/try/*/signal/*
   
   // Returning result of invocation to caller.
   return
         
