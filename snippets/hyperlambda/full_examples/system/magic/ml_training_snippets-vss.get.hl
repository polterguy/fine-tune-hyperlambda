
/*
 * Retrieves training snippets from `ml_training_snippets` using OpenAI embeddings and vector similarity search (VSS).
 *
 * This Hyperlambda HTTP `GET` endpoint allows root users to perform semantic search over the `ml_training_snippets` table
 * using OpenAI embeddings. It retrieves records ranked by vector similarity to a [filter] string input, with optional
 * filtering by `type` and support for paging via `limit` and `offset`.
 *
 * ### Access Control:
 * - Only users with the `root` role may invoke this endpoint.
 *   Enforced using [auth.ticket.verify:root].
 *
 * ### Arguments:
 * - `filter` (string): Required. The string query to embed and use as the basis for VSS search.
 * - `type` (string): Optional. Filters results by matching the `type` column.
 * - `limit` (long): Optional. Limits the number of returned records. Defaults to `10`.
 * - `offset` (long): Optional. Offsets the results for pagination.
 *
 * ### Behavior:
 * 1. **Authorization & Validation**:
 *    - Requires the `filter` string to be present and between 1 and 1000 characters.
 * 2. **Retrieve Embedding Model**:
 *    - Queries the `ml_types` table to determine the vector model to use for the specified `type`.
 * 3. **Generate Embedding**:
 *    - Sends a request to the OpenAI `/v1/embeddings` API using the configured model and API key.
 *    - Validates the response and logs + throws an error if OpenAI returns an error.
 * 4. **Query VSS-Indexed Table**:
 *    - Performs a vector similarity search in the `vss_ml_training_snippets` shadow table using the generated embedding.
 *    - Joins results with `ml_training_snippets` using `rowid`.
 *    - Applies optional `type` filter and paginates using `limit` and `offset`.
 * 5. **Result Post-processing**:
 *    - Converts `embedding_vss` column to a boolean (`true` if it exists, `false` otherwise) to reduce bandwidth.
 *    - Appends a `tokens` field to each record, indicating the total token count of `prompt + completion` using OpenAI's tokenizer.
 * 6. **Returns a list of relevant records** sorted by vector similarity, each including:
 *    - `id`, `created`, `type`, `pushed`, `uri`, `prompt`, `completion`, `filename`, `cached`, `meta`, `embedding_vss`, and `tokens`.
 *
 * ### Returns:
 * - A list of semantically similar `ml_training_snippets` records with token counts and filtered by type if specified.
 *
 * ### Example Response:
 * ```json
 * [
 *   {
 *     "id": 1204,
 *     "created": "2024-12-01T15:22:00Z",
 *     "type": "faq",
 *     "pushed": 1,
 *     "uri": "/support/chat",
 *     "prompt": "How do I reset my password?",
 *     "completion": "To reset your password, go to the login page and click 'Forgot password'.",
 *     "embedding_vss": true,
 *     "tokens": 34
 *   }
 * ]
 * ```
 *
 * ### Notes:
 * - This endpoint leverages the `vss_search()` function and requires your database to support VSS (Vector Similarity Search).
 * - The OpenAI embedding call requires a valid key under the config path `magic:openai:key`.
 * - Useful for building intelligent search experiences across training data or fine-tuning datasets.
 */
.arguments
   limit:long
   offset:long
   filter:string
   type:string

// Verifying user is authorized to access endpoint.
auth.ticket.verify:root

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/filter
validators.string:x:@.arguments/*/filter
   min:1
   max:1000

// Applying defaults.
validators.default:x:@.arguments
   limit:int:10

// Retrieving embeddings.
.token
set-value:x:@.token
   strings.concat
      .:"Bearer "
      config.get:"magic:openai:key"

// Figuring out embeddings model to use.
.embeddings-model
data.connect:[generic|magic]
   data.read
      table:ml_types
      columns
         vector_model
      where
         and
            type.eq:x:@.arguments/*/type
   set-value:x:@.embeddings-model
      get-value:x:@data.read/*/*/vector_model

// Retrieving embedding for prompt.
http.post:"https://api.openai.com/v1/embeddings"
   headers
      Authorization:x:@.token
      Content-Type:application/json
   payload
      input:x:@.arguments/*/filter
      model:x:@.embeddings-model
   convert:true

// Sanity checking above invocation.
if
   not
      and
         mte:x:@http.post
            .:int:200
         lt:x:@http.post
            .:int:300
   .lambda

      // Oops, error - Logging error and returning OpenAI's HTTP status code to caller.
      lambda2hyper:x:@http.post
      log.error:Something went wrong while invoking OpenAI
         message:x:@http.post/*/content/*/error/*/message
         error:x:@lambda2hyper
      throw:x:@http.post/*/content/*/error/*/message
         public:bool:true
         status:x:@http.post

// Converting from JSON string to byte array.
floatArray2bytes:x:@http.post/*/content/*/data/0/*/embedding/*

// Opening up our database connection.
data.connect:[generic|magic]

   .sql:@"
select vss.distance, id, created, type, pushed, uri, prompt, completion, filename, cached, meta, embedding as embedding_vss
   from vss_ml_training_snippets as vss
    	inner join ml_training_snippets ts on ts.id = vss.rowid
   where
      vss_search(vss.embedding_vss, @embedding)"

   // Further parametrising invocation if we should.
   if
      exists:x:@.arguments/*/type
      .lambda
         set-value:x:@.sql
            strings.concat
               get-value:x:@.sql
               .:" and type = @type"
         unwrap:x:+/*/*
         add:x:@if/./*/data.select
            .
               @type:x:@.arguments/*/type
   if
      exists:x:@.arguments/*/limit
      .lambda
         set-value:x:@.sql
            strings.concat
               get-value:x:@.sql
               .:" limit "
               get-value:x:@.arguments/*/limit
   if
      exists:x:@.arguments/*/offset
      .lambda
         set-value:x:@.sql
            strings.concat
               get-value:x:@.sql
               .:" offset "
               get-value:x:@.arguments/*/offset

   // Executing SQL towards database.
   data.select:x:@.sql
      @embedding:x:@floatArray2bytes

   // Changing embedding to a boolean value to preserve bandwidth, and returning token count.
   for-each:x:@data.select/*

      // Changing embedding to boolean to preserve bandwidth.
      if
         not-null:x:@.dp/#/*/embedding_vss
         .lambda
            set-value:x:@.dp/#/*/embedding_vss
               .:bool:true
      else
         set-value:x:@.dp/#/*/embedding_vss
            .:bool:false

      // Adding token count for each snippet.
      strings.concat
         get-value:x:@.dp/#/*/prompt
         .:"\r\n\r\n"
         get-value:x:@.dp/#/*/completion
      openai.tokenize:x:@strings.concat
      unwrap:x:+/*/*
      add:x:@.dp/#
         .
            tokens:x:@openai.tokenize

   // Returning result of above read invocation to caller.
   return-nodes:x:@data.select/*
