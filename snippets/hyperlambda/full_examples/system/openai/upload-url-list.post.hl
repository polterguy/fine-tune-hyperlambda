
/*
 * Scrapes all URLs listed in an uploaded CSV file and optionally vectorizes the resulting training data.
 *
 * This endpoint uses the "Spice" feature to import **only the explicitly listed URLs**, bypassing typical crawler behavior.
 * It supports optional post-processing using vectorization and provides real-time frontend feedback through a websocket channel.
 *
 * INPUT PARAMETERS:
 * - [type:string]: Logical model category to associate scraped content with.
 * - [feedback-channel:string]: WebSocket channel name to stream feedback messages during scraping/vectorization.
 * - [vectorize:bool]: If true, triggers vectorization after scraping (default: false).
 * - [file:*]: CSV file containing URLs. Must be multipart form data with the following subfields:
 *     - [name]: Filename of the uploaded CSV.
 *     - [stream]: Binary stream representing the CSV file.
 *
 * ENDPOINT BEHAVIOR:
 *
 * 1. **Authorization & Validation**:
 *    - Ensures only root users can invoke this endpoint.
 *    - Validates that [type], [file.name], and [file.stream] are all present.
 *    - Defaults [vectorize] to false if not provided.
 *
 * 2. **File Handling**:
 *    - Reads and parses the uploaded CSV file into a lambda structure using [csv2lambda].
 *    - Performs basic validation to ensure:
 *       - Each row has exactly one column.
 *       - The column contains valid HTTP/HTTPS URLs.
 *    - If validation fails, notifies the frontend via [feedback-channel] and aborts.
 *
 * 3. **Logging & Preparation**:
 *    - Logs the number of URLs successfully parsed.
 *    - Pushes arguments and URL data into a [fork] block for background asynchronous processing.
 *
 * 4. **Scraping Logic (Asynchronous)**:
 *    - Iterates through all URLs.
 *    - For each URL:
 *       - Calls [magic.ai.url.scrape] with scraping options:
 *           - [lists], [images], and [code] all set to false.
 *           - Ensures only page content is captured.
 *       - Signals the frontend after each scrape for progress updates.
 *       - Catches and logs any errors individually without interrupting the full process.
 *
 * 5. **Post-Scraping Actions**:
 *    - Notifies root users and frontend channel that scraping is completed.
 *    - If [vectorize:true], invokes [magic.ai.vectorise] on the specified [type].
 *       - Signals the frontend when vectorization is complete.
 *
 * 6. **Final Response**:
 *    Returns a [success] result along with the number of URLs processed.
 *
 * This endpoint is ideal for scenarios requiring curated web content ingestion from a known list of URLs—
 * such as bulk FAQ imports, product pages, or long-form documentation—combined with real-time monitoring and optional embedding generation.
 */

.arguments
   type:string
   feedback-channel:string
   vectorize:bool
   file:*

// Accepts only multipart form data!!
.accept:multipart/form-data

// Ensures user is authorized to access endpoint.
auth.ticket.verify:root

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/type
validators.mandatory:x:@.arguments/*/file
validators.mandatory:x:@.arguments/*/file/*/name
validators.mandatory:x:@.arguments/*/file/*/stream

// Applying defaults.
validators.default:x:@.arguments
   vectorize:bool:false

// Reading file data from stream.
io.stream.read:x:@.arguments/*/file/*/stream

// Converting file to lambda object.
csv2lambda:x:@io.stream.read

// Sanity checking file.
if
   or
      mt
         get-count:x:@csv2lambda/0/*
         .:int:1
      and
         not
            strings.starts-with:x:@csv2lambda/0/0
               .:"http://"
         not
            strings.starts-with:x:@csv2lambda/0/0
               .:"https://"
   .lambda

      // Oops, bogus file!
      log.info:URL list file not in correct format
         filename:x:@.arguments/*/file/*/name
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:File not valid. A URL list file must have only one column, and contain only URLs in its single column.
            type:error
      return
         result:error

// Doing some basic logging.
get-count:x:@csv2lambda/*
log.info:URL list successfully uploaded
   count:x:@get-count
   type:x:@.arguments/*/type

// Scraping on a background thread.
add:x:./*/fork/*/.urls
   get-nodes:x:@csv2lambda/*
insert-before:x:./*/fork/0
   get-nodes:x:@.arguments
fork

   // Buffer containing all URLs we've got.
   .urls

   // Looping through each URL in our list of URLs.
   for-each:x:@.urls/*/*

      // Making sure we catch exceptions.
      try

         /*
          * Invoking crawl implementation file, now with explicit list of links,
          * informing invocation that we do NOT want to process links.
          */
         execute:magic.ai.url.scrape
            url:x:@.dp/#
            type:x:@.arguments/*/type
            feedback-channel:x:@.arguments/*/feedback-channel
            lists:bool:false
            images:bool:false
            code:bool:false
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:------------------------------------------------------------------------------------------------------------------------
               type:info

      .catch

         // Informing user of what went wrong.
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:x:@.arguments/*/message
               type:warning

   /*
    * Crawling is done.
    *
    * Making sure we notify client that we're done and do some logging.
    */
   sockets.signal:magic.backend.message
      roles:root
      args
         message:Done creating OpenAI training data from URL list
         type:success

   // Checking if we're supposed to vectorize model.
   if
      eq:x:@.arguments/*/vectorize
         .:bool:true
      .lambda

         // Vectorizing model.
         execute:magic.ai.vectorise
            type:x:@.arguments/*/type
            feedback-channel:x:@.arguments/*/feedback-channel
            .onafter

               // Signaling frontend.
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:Done!
                     type:success
   else

      // Signaling frontend.
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:Done!
            type:success

   // Basic logging.
   log.info:OpenAI training data successfully created from URL list
      type:x:@.arguments/*/type

// Returning success to caller.
yield
   result:success
   count:x:@get-count
