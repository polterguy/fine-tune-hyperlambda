/*
 * Creates a system message using OpenAI GPT-4, dynamically populating a template based on scraped website content.
 *
 * This slot enables programmatic generation of contextualized system messages by merging structured templates with
 * real-world content. It uses a specified [url] as the source for context, a [template] containing placeholders (e.g., [XYZ]),
 * and an [instruction] that tells GPT-4 how to interpret and fill the template.
 *
 * ARGUMENTS:
 * - [url:string] (required): The website URL to scrape for contextual data.
 * - [template:string] (required): A string containing placeholder fields (e.g., [TITLE], [SUMMARY], etc.).
 * - [instruction:string] (required): A directive telling GPT-4 how to process the template using the content from [url].
 *
 * EXECUTION FLOW:
 *
 * 1. **Validation**:
 *    - Ensures that [url], [template], and [instruction] are present and that [url] is valid.
 *
 * 2. **Scraping Website Content**:
 *    - Uses [magic.http.scrape-url] to retrieve RAG-style prompt-completion pairs from the specified [url].
 *    - If scraping fails, throws a public 400/500 error.
 *
 * 3. **Context Building**:
 *    - Iteratively compiles a [context] string using available prompt-completion pairs.
 *    - Stops appending once the token count exceeds 4000 (to stay within GPT-4 context limits).
 *
 * 4. **Preparing GPT-4 Request**:
 *    - Retrieves the OpenAI API key from configuration.
 *    - Builds a prompt sequence using:
 *       - [instruction] as the system prompt.
 *       - [template] as user input (providing structure).
 *       - [context] as additional user input (providing content).
 *    - Sends a streaming-enabled POST request to OpenAI's `/v1/chat/completions` endpoint using the `gpt-4o` model.
 *
 * 5. **Error Handling**:
 *    - Validates that the response is in the 200â€“299 range.
 *    - Logs and throws a detailed error if OpenAI returns an error or invalid response.
 *
 * 6. **Formatting and Response**:
 *    - Cleans up the GPT-generated message by normalizing newlines.
 *    - Returns the final system message to the caller as a single string.
 *
 * USE CASES:
 * - Automatically create system prompts for chatbots based on page content.
 * - Convert structured templates into personalized messages using real content.
 * - Build contextual onboarding or help messages by scraping support pages.
 *
 * This slot enables dynamic generation of highly contextualized system messages,
 * ideal for use in GPT fine-tuning, AI onboarding flows, or dynamic assistant configuration.
 */


slots.create:magic.ai.create-system-message

   // Sanity checking invocation.
   validators.mandatory:x:@.arguments/*/url
   validators.mandatory:x:@.arguments/*/template
   validators.mandatory:x:@.arguments/*/instruction
   validators.url:x:@.arguments/*/url

   // Retrieving context.
   execute:magic.http.scrape-url
      url:x:@.arguments/*/url
   if
      not-null:x:@execute
      .lambda

         // Oops ...!!
         throw:Could not scrape URL
            public:bool:true
            status:x:@execute

   // Building our context based upon the [url] specified.
   .context:
   while
      and
         exists:x:@execute/0
         lt
            openai.tokenize:x:@.context
            .:int:4000
      .lambda

         // Temporary value.
         .tmp
         set-value:x:@.tmp
            strings.concat
               get-value:x:@.context
               .:"\n\n"
               get-value:x:@execute/0/*/prompt
               .:"\n\n"
               get-value:x:@execute/0/*/completion
         if
            lt
               openai.tokenize:x:@.tmp
               .:int:4000
            .lambda

               // Still below [max_tokes].
               set-value:x:@.context
                  get-value:x:@.tmp

         // Removing top snippet.
         remove-nodes:x:@execute/0/*/snippets/0
         if
            not-exists:x:@execute/0/*/snippets/0
            .lambda

               // Removing currently iterated URL.
               remove-nodes:x:@execute/0

   // Trimming result.
   set-value:x:@.context
      strings.trim:x:@.context

   // Retrieving OpenAI API token from configuration settings.
   .token
   set-value:x:@.token
      strings.concat
         .:"Bearer "
         config.get:"magic:openai:key"

   // Invokes OpenAI.
   http.post:"https://api.openai.com/v1/chat/completions"
      convert:bool:true
      headers
         Authorization:x:@.token
         Content-Type:application/json
      payload
         model:gpt-4o
         max_tokens:int:3600
         temperature:decimal:0.3
         messages
            .
               role:system
               content:x:@.arguments/*/instruction
            .
               role:user
               content:x:@.arguments/*/template
            .
               role:user
               content:x:@.context

   // Sanity checking above invocation.
   if
      not
         and
            mte:x:@http.post
               .:int:200
            lt:x:@http.post
               .:int:300
      .lambda

         // Oops, error - Logging error and returning status 500 to caller.
         lambda2hyper:x:@http.post
         log.error:Something went wrong while invoking OpenAI
            message:x:@http.post/*/content/*/error/*/message
            status:x:@http.post
            error:x:@lambda2hyper
         throw:Something went wrong while invoking OpenAI
            message:x:@http.post/*/content/*/error/*/message
            status:x:@http.post
            error:x:@lambda2hyper

   // Returning answer to caller.
   strings.replace:x:@http.post/*/content/*/choices/0/*/message/*/content
      .:"\r"
      .:""
   strings.replace:x:-
      .:"\n"
      .:"\r\n"
   return:x:-
