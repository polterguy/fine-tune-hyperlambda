/*
 * This endpoint converts text to speech using OpenAI's TTS API and streams the audio back to a specified WebSocket session.
 *
 * INPUT PARAMETERS:
 * - [content:string]: The text message that will be converted to speech.
 * - [session:string]: The WebSocket session ID for sending the resulting audio stream to the client.
 *
 * The endpoint workflow includes the following steps:
 *
 * 1. **Validation**:
 *    Ensures that both [content] and [session] arguments are provided using [validators.mandatory].
 *
 * 2. **Threading**:
 *    Inserts the argument nodes before a [fork] operation to ensure they are available inside the new thread.
 *    The [fork] block runs asynchronously, allowing the outer endpoint to return quickly while processing continues in the background.
 *
 * 3. **Token Retrieval and Setup**:
 *    Retrieves the OpenAI API key from configuration using [config.get].
 *    If an API key is passed in the arguments under [api_key], it overrides the default key.
 *    The final token is prefixed with `"Bearer "` and stored in [.token] for use in the authorization header.
 *
 * 4. **Calling OpenAI's Text-to-Speech API**:
 *    Performs an HTTP POST to `https://api.openai.com/v1/audio/speech` using:
 *    - `model: tts-1`
 *    - `input: content from arguments`
 *    - `voice: alloy` (a specific OpenAI TTS voice model)
 *    - `response_format: mp3`
 *    - `speed: 1.0` (normal playback speed)
 *    The request is JSON-based and sets appropriate headers including Authorization and Accept types.
 *
 * 5. **Audio Conversion and Delivery**:
 *    - Converts the MP3 binary response into base64 using [convert] with type:base64.
 *    - Uses [unwrap] to flatten the node structure for easier access.
 *    - Sends the resulting base64 audio via [sockets.signal] to the WebSocket client specified by the [session] argument.
 *      The audio is passed as an [args.audio] parameter to the client.
 *
 * 6. **Final Response**:
 *    Returns a result node with value "success" using [yield], signaling that the request was accepted and is being processed in the background.
 *
 * This endpoint is optimized for non-blocking, real-time TTS audio streaming, and is ideal for chat applications or voice assistants.
 */

.arguments
   content:string
   session:string

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/content
validators.mandatory:x:@.arguments/*/session

// Creating a new thread to return before timeout.
insert-before:x:../*/fork/0
   get-nodes:x:@.arguments
fork

   // Retrieving token used to invoke OpenAI.
   .token
   config.get:"magic:openai:key"
   set-value:x:@.token
      strings.concat
         .:"Bearer "
         get-first-value
            get-value:x:@.arguments/*/api_key
            config.get:"magic:openai:key"

   // Invoking OpenAI's API.
   http.post:"https://api.openai.com/v1/audio/speech"
      convert:bool:true
      headers
         Authorization:x:@.token
         Content-Type:application/json
         Accept:text/event-stream
      payload
         model:tts-1
         input:x:@.arguments/*/content
         voice:alloy
         response_format:mp3
         speed:decimal:1.0

   // Sending speech to client.
   convert:x:@http.post/*/content
      type:base64
   unwrap:x:+/*/*
   sockets.signal:x:@.arguments/*/session
      args
         audio:x:@http.post/*/content

yield
   result:success
