/*
 * Serves as a lightweight router for retrieving dynamic responses from a predefined
 * Hyperlambda endpoint file.
 *
 * Accepts a variety of input arguments such as 'prompt', 'type', 'chat', and others,
 * which are forwarded directly to the internal logic contained in [/system/openai/chat.get.hl].
 * This allows for clean separation between the routing logic and actual implementation details.
 *
 * The contents of the [.arguments] node are passed along to the [execute-file] slot,
 * ensuring all input parameters are available to the underlying file logic.
 *
 * The results from the file are then returned to the client using [return-nodes],
 * effectively making this wrapper endpoint a simple forwarder to deeper, modular functionality.
 */
.arguments
   prompt:string
   type:string
   references:bool
   chat:bool
   recaptcha_response:string
   user_id:string
   session:string
   stream:bool
   data:string
   referrer:string

// Forwarding to get Hyperlambda file.
add:x:+
   get-nodes:x:@.arguments/*
execute-file:/system/openai/chat.get.hl

// Returning result to caller.
return-nodes:x:-/*
