/*
 * Processes a paginated set of fine-tune records to generate file-level Hyperlambda comments using OpenAI.
 *
 * Requires [limit] and [offset] parameters to determine which database rows to process.
 * Loads a predefined system message from a markdown file using [io.file.load] and stores it in [.system-message].
 *
 * Connects to the 'fine-tune' database using [data.connect] and selects relevant [hyperlambda] records.
 * For each record:
 *  - Converts [code] to Hyperlambda format with inline comments using [hyper2lambda].
 *  - Prepends the prompt as a top-level comment using [insert-before].
 *  - Re-serializes to Hyperlambda using [lambda2hyper].
 *  - Logs the transformation with [log.info].
 *  - Retrieves context with [openai-context-from-database].
 *  - Invokes OpenAI's API via [openai-query] with context, instruction, and transformed code.
 *  - Generates a filename from the [hyperlambda_id] and saves the AI response using [io.file.save].
 *
 * Waits 5 seconds between iterations using [sleep] to avoid rate limiting from OpenAI.
 */
.arguments
   limit:long
   offset:long

// Ensuring both arguments are specified by caller!
validators.mandatory:x:@.arguments/*/limit
validators.mandatory:x:@.arguments/*/offset

// Loading our system message file.
.system-message
set-value:x:@.system-message
   io.file.load:/modules/fine-tune-hyperlambda/system-message-synthesiser.md

// Connecting to our fine-tune database.
data.connect:fine-tune

   // Selecting records.
   data.select:"select * from hyperlambda where code like '%.arguments%' and is_static = 0 and synthesised = 0 limit @limit offset @offset"
      @limit:x:@.arguments/*/limit
      @offset:x:@.arguments/*/offset

   // Iterating through records.
   for-each:x:@data.select/*

      // Transforming prompt + code into a file-level comment + original code.
      hyper2lambda:x:@.dp/#/*/code
         comments:true
      unwrap:x:+/*/*
      insert-before:x:@hyper2lambda/0
         .
            ..:x:@.dp/#/*/prompt

      // Transforming to Hyperlambda again.
      .hl
      set-value:x:@.hl
         lambda2hyper:x:@hyper2lambda/*
            comments:true

      // Doing some logging.
      log.info:Invoking OpenAI
         prompt:x:@.hl
         
            
      /*
       * Returns context for the specified [query] from the specified [type],
       * and returns to caller.
       *
       * Optionally add [threshold] and [max_tokens] to specify similarity and maximum
       * tokens to return. [type] is a machine learning type from your ml_types database table in
       * your magic database.
       */
      execute:magic.workflows.actions.execute
         name:openai-context-from-database
         filename:/modules/openai/workflows/actions/openai-context-from-database.hl
         arguments
            type:magic-documentation
            query:x:@.hl
            threshold:decimal:0.3
            max_tokens:int:3000

      /*
       * Invokes OpenAI's chat API with the specified [model], [max_tokens], [context],
       * [instruction] and [query].
       *
       * Will use the default API key found from configurations.
       *
       * [context] is additional data you can supply to OpenAI such that it responds using
       * your data as its source for information. [instruction] is a system message allowing
       * you to change how OpenAI responds.
       */
      execute:magic.workflows.actions.execute
         name:openai-query
         filename:/modules/openai/workflows/actions/openai-query.hl
         arguments
            model:gpt-4o
            max_tokens:int:1500
            instruction:x:@.system-message
            context:x:@execute/@execute/*/context
            query:x:@.hl

      // Creating a unique filename
      .filename
      set-value:x:@.filename
         strings.concat
            .:/modules/fine-tune-hyperlambda/snippets/hyperlambda/synthesised/
            get-value:x:@.dp/#/*/hyperlambda_id
            .:.hl

      // Saving to file system.
      io.file.save:x:@.filename
         get-value:x:@execute/*/answer

      // To avoid 429 from OpenAI we wait for 5 seconds before we execute the next record.
      sleep:5000
