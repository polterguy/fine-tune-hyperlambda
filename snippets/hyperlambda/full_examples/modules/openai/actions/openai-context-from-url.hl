
/*
 * Creates an HTTP endpoint that scrapes training snippets from the specified [url],
 * then composes a [context] response based on the concatenated [prompt] and [completion]
 * pairs found, limiting total size based on [max_tokens].
 *
 * 1. [.arguments]
 *    * [url]:string - Mandatory. The URL to scrape snippets from.
 *    * [max_tokens]:int - Optional. Token limit for resulting context. Defaults to 4000.
 *    * [throw]:bool - Optional. If true, throws an error if the scrape fails.

 * 2. [validators.mandatory], [validators.default]
 *    * Ensures [url] is present, and applies a default for [max_tokens] if missing.

 * 3. [execute:magic.http.scrape-url]
 *    * Invokes a slot that scrapes the given [url] and returns training snippets in [prompt]/[completion] pairs.

 * 4. [if] and [throw]
 *    * If [throw] is true and no scrape result is found, the code throws a public exception with the HTTP status code from [execute].

 * 5. [.context], [while]
 *    * Initializes and appends new training text into [.context] while keeping the token count below [max_tokens].
 *    * It builds [.tmp] using [prompt] + [completion] strings and evaluates token size before adding to [.context].

 * 6. [remove-nodes]
 *    * Iteratively removes snippets from [execute] results once processed to avoid re-use.

 * 7. [strings.trim]
 *    * Final cleanup to remove leading/trailing whitespace from the generated context string.

 * 8. [yield]
 *    * Returns the full composed [context] string as the final output.

 * Use cases:
 * * Building dynamic system messages or LLM prompt context from website data.
 * * Ensuring context size respects token boundaries for AI completions.
 */
.arguments
   url:string
   max_tokens:int
   throw:bool

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/url

// Applying default values for optional arguments.
validators.default:x:@.arguments
   max_tokens:int:4000

// Retrieving context.
execute:magic.http.scrape-url
   url:x:@.arguments/*/url
if
   and
      get-value:x:@.arguments/*/throw
      not-null:x:@execute
   .lambda
      throw:Could not scrape URL
         public:bool:true
         status:x:@execute

// Building our context return value.
.context:
while
   and
      exists:x:@execute/0
      lt
         openai.tokenize:x:@.context
         convert:x:@.arguments/*/max_tokens
            type:int
   .lambda

      // Temporary value.
      .tmp
      set-value:x:@.tmp
         strings.concat
            get-value:x:@.context
            .:"\n\n"
            get-value:x:@execute/0/*/prompt
            .:"\n\n"
            get-value:x:@execute/0/*/completion
      if
         lt
            openai.tokenize:x:@.tmp
            convert:x:@.arguments/*/max_tokens
               type:int
         .lambda

            // Still below [max_tokes].
            set-value:x:@.context
               get-value:x:@.tmp

      // Removing top snippet.
      remove-nodes:x:@execute/0/*/snippets/0
      if
         not-exists:x:@execute/0/*/snippets/0
         .lambda

            // Removing currently iterated URL.
            remove-nodes:x:@execute/0

// Trimming result.
set-value:x:@.context
   strings.trim:x:@.context

// Returning result to caller.
yield
   context:x:@.context
