
/*
 * This Hyperlambda code calculates the maximum context and request tokens for a model by first subtracting half of the max_tokens value from 32768, and then dividing the result by 2. It uses [math.subtract] to perform the subtraction and [math.divide] to perform the division. The results are then set to [max_context_tokens] and [max_request_tokens] using [set-value]. The code effectively splits the available tokens evenly between context and request. 
 * 
 * 1. [math.divide] - Divides the result of the subtraction by 2.
 * 2. [math.subtract] - Subtracts half of the max_tokens from 32768.
 * 3. [get-value:x:@.model/*/max_tokens] - Retrieves the max_tokens value.
 * 4. [set-value:x:@.model/*/max_context_tokens] - Sets the max_context_tokens to the result of the division.
 * 5. [set-value:x:@.model/*/max_request_tokens] - Sets the max_request_tokens to the result of the division.
 */
case:gpt-4-32k-0314
   math.divide
      math.subtract:int:32768
         get-value:x:@.model/*/max_tokens
      .:int:2
   set-value:x:@.model/*/max_context_tokens
      get-value:x:@math.divide
   set-value:x:@.model/*/max_request_tokens
      get-value:x:@math.divide
