
/*
 * This Hyperlambda code snippet checks if the number of tokens required by the JSON representation of a lambda object exceeds a specified maximum context token limit. If the token count is greater, it throws an exception with a message "Result too large, try to limit your result" and sets the HTTP status to 400, making the error public. 
 * 
 * 1. [if] - Begins a conditional statement.
 * 2. [mt] - Compares two values, checking if the first is greater than the second.
 * 3. [openai.tokenize] - Calculates the token count of the JSON representation of a lambda object.
 * 4. [get-value] - Retrieves the maximum context token limit from the arguments.
 * 5. [.lambda] - Contains the code to execute if the condition is true.
 * 6. [throw] - Throws an exception with a specified message and status code.
 * 7. [status] - Sets the HTTP status code for the exception.
 * 8. [public] - Indicates whether the exception message should be public.
 */
if
   mt
      openai.tokenize:x:@lambda2json
      get-value:x:@.arguments/@.arguments/*/max_context_tokens
   .lambda
      throw:Result too large, try to limit your result
         status:int:400
         public:bool:true
