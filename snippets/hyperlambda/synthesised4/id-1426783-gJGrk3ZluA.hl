
/*
 * This Hyperlambda code checks if the number of tokens required for a given input exceeds a specified maximum context token limit. If the input token count is greater than the allowed limit, it throws an exception with a message indicating that the result is too large, along with an HTTP status code of 400. 
 * 
 * 1. [if] - Initiates a conditional statement.
 * 2. [mt] - Compares two values and returns true if the first is more than the second.
 * 3. [openai.tokenize] - Calculates the number of tokens for the input specified by the expression.
 * 4. [get-value] - Retrieves the maximum context token limit from the arguments.
 * 5. [.lambda] - Contains the code to execute if the condition is true.
 * 6. [throw] - Throws an exception with a specified message and status code.
 * 7. [status] - Sets the HTTP status code for the exception.
 * 8. [public] - Indicates whether the exception message should be public.
 */
if
   mt
      openai.tokenize:x:@lambda2json
      get-value:x:@.arguments/@.arguments/*/max_context_tokens
   .lambda
      throw:Result too large, try to limit your result
         status:int:400
         public:bool:true
