
/*
 * This Hyperlambda code defines a dynamic slot named "magic.ai.load-sitemap" that retrieves and processes sitemap URLs. It validates input arguments, retrieves sitemaps using HTTP GET requests, and processes XML content to extract URLs, ensuring they don't exceed a specified count. The code handles errors and signals feedback through a feedback channel. It also sorts and filters URLs based on specified patterns and conditions, returning a list of URLs and sitemap status.
 * 
 * 1. [slots.create] - Creates a dynamic slot named "magic.ai.load-sitemap".
 * 2. [validators.mandatory] - Ensures required arguments "sitemap" and "max" are provided.
 * 3. [validators.integer] - Validates "max" as an integer within a specified range.
 * 4. [validators.default] - Sets default values for arguments if not provided.
 * 5. [if] - Checks for the existence of headers and sets default headers if missing.
 * 6. [try] - Attempts to process each sitemap URL.
 * 7. [for-each] - Iterates over sitemap URLs and retrieves them.
 * 8. [http.get] - Performs HTTP GET requests to retrieve sitemap content.
 * 9. [if] - Checks HTTP response status and content type.
 * 10. [xml2lambda] - Converts XML content to a lambda structure.
 * 11. [for-each] - Iterates over URLs in the sitemap and processes them.
 * 12. [signal] - Recursively invokes the slot for nested sitemaps.
 * 13. [sort] - Sorts URLs based on their lengths.
 * 14. [while] - Loops to filter and add URLs based on conditions.
 * 15. [return-nodes] - Returns the processed URLs and sitemap status.
 * 16. [.catch] - Handles errors and signals feedback through a feedback channel.
 */
hyper2lambda
   slots.create:magic.ai.load-sitemap
      validators.mandatory:x:@.arguments/*/sitemap/*/[0,1]
      validators.integer:x:@.arguments/*/max
         min:1
         max:10000
      validators.default:x:@.arguments
         max:int:25
      if
         not-exists:x:@.arguments/*/headers
         .lambda
            add:x:@.arguments
               .
                  headers
      validators.default:x:@.arguments/*/headers
         User-Agent:AINIRO-Crawler 2.0
         Accept-Encoding:identity
         Accept:text/xml
      .urls
      .has-sitemap:bool:false
      try
         for-each:x:@.arguments/*/sitemap/*/[0,25]
            strings.concat
               .:"Retrieving sitemap "
               get-value:x:@.dp/#
            unwrap:x:+/**
            sockets.signal:x:@.arguments/*/feedback-channel
               args
                  message:x:@strings.concat
                  type:info
            sleep:100
            if
               lt
                  get-count:x:@.urls/*
                  .:int:10000
               .lambda
                  .domain
                  strings.split:x:@.dp/#
                     .:/
                  set-value:x:@.domain
                     strings.concat
                        get-value:x:@strings.split/0
                        .://
                        get-value:x:@strings.split/1
                  add:x:./*/http.get
                     get-nodes:x:@.arguments/*/headers
                  http.get:x:@.dp/#
                     timeout:60
                  if
                     and
                        not
                           mte:x:@http.get
                              .:int:200
                        not
                           lt:x:@http.get
                              .:int:300
                     .lambda
                        log.error:Sitemap invocation did not return success status
                           url:x:@.dp/#
                           status:x:@http.get
                        throw:Could not retrieve sitemap
                  if
                     not
                        or
                           strings.starts-with:x:@http.get/*/headers/*/Content-Type
                              .:application/xml
                           strings.starts-with:x:@http.get/*/headers/*/content-type
                              .:application/xml
                           strings.starts-with:x:@http.get/*/headers/*/Content-Type
                              .:text/xml
                           strings.starts-with:x:@http.get/*/headers/*/content-type
                              .:text/xml
                     .lambda
                        throw:Sitemap was not XML
                  else
                     set-value:x:@.has-sitemap
                        .:bool:true
                     strings.trim:x:@http.get/*/content
                     xml2lambda:x:@strings.trim
                     for-each:x:"@xml2lambda/*/urlset/*/url/*/loc/*/\\#text"
                        if
                           lt
                              get-count:x:@.urls/*
                              .:int:10000
                           .lambda
                              .url
                              set-value:x:@.url
                                 get-value:x:@.dp/#
                              if
                                 and
                                    not
                                       strings.starts-with:x:@.dp/#
                                          .:"http://"
                                    not
                                       strings.starts-with:x:@.dp/#
                                          .:"https://"
                                 .lambda
                                    set-value:x:@.url
                                       strings.concat
                                          get-value:x:@.domain
                                          get-value:x:@.dp/#
                              if
                                 not-exists:x:@.urls/*/={@.url}
                                 .lambda
                                    unwrap:x:+/*/*
                                    add:x:@.urls
                                       .
                                          .:x:@.url
                     for-each:x:"@xml2lambda/*/urlset/*/url/*/loc/*/\\#cdata-section"
                        if
                           lt
                              get-count:x:@.urls/*
                              .:int:10000
                           .lambda
                              .url
                              set-value:x:@.url
                                 get-value:x:@.dp/#
                              if
                                 and
                                    not
                                       strings.starts-with:x:@.dp/#
                                          .:"http://"
                                    not
                                       strings.starts-with:x:@.dp/#
                                          .:"https://"
                                 .lambda
                                    set-value:x:@.url
                                       strings.concat
                                          get-value:x:@.domain
                                          get-value:x:@.dp/#
                              if
                                 not-exists:x:@.urls/*/={@.url}
                                 .lambda
                                    unwrap:x:+/*/*
                                    add:x:@.urls
                                       .
                                          .:x:@.url
                     for-each:x:"@xml2lambda/*/sitemapindex/*/sitemap/*/[0,25]/loc/*/\\#cdata-section"
                        if
                           lt
                              get-count:x:@.urls/*
                              .:int:10000
                           .lambda
                              add:x:./*/signal
                                 get-nodes:x:@.arguments/*/headers
                              unwrap:x:+/**
                              signal:magic.ai.load-sitemap
                                 max:int:10000
                                 feedback-channel:x:@.arguments/*/feedback-channel
                                 filter-on-url:x:@.arguments/*/filter-on-url
                                 sitemap
                                    .:x:@.dp/#
                              add:x:@.urls
                                 get-nodes:x:@signal/*/urls/*
                              if
                                 and
                                    eq:x:@signal/*/has-sitemap
                                       .:bool:false
                                    eq
                                       get-count:x:@.urls/*
                                       .:int:0
                                 .lambda
                                    set-value:x:@.has-sitemap
                                       .:bool:false
                     for-each:x:"@xml2lambda/*/sitemapindex/*/sitemap/*/[0,25]/loc/*/\\#text"
                        if
                           lt
                              get-count:x:@.urls/*
                              .:int:10000
                           .lambda
                              unwrap:x:+/**
                              signal:magic.ai.load-sitemap
                                 max:int:10000
                                 feedback-channel:x:@.arguments/*/feedback-channel
                                 filter-on-url:x:@.arguments/*/filter-on-url
                                 sitemap
                                    .:x:@.dp/#
                              add:x:@.urls
                                 get-nodes:x:@signal/*/urls/*
                              if
                                 and
                                    eq:x:@signal/*/has-sitemap
                                       .:bool:false
                                    eq
                                       get-count:x:@.urls/*
                                       .:int:0
                                 .lambda
                                    set-value:x:@.has-sitemap
                                       .:bool:false
         .total
         set-value:x:@.total
            get-count:x:@.urls/*
         sort:x:@.urls/*
            if
               lt
                  strings.length:x:@.lhs/#
                  strings.length:x:@.rhs/#
               .lambda
                  set-value:x:@.result
                     .:int:-1
            else-if
               mt
                  strings.length:x:@.lhs/#
                  strings.length:x:@.rhs/#
               .lambda
                  set-value:x:@.result
                     .:int:1
            else
               set-value:x:@.result
                  .:int:0
         .match
            if
               strings.ends-with:x:@.arguments/*/pattern
                  .:*
               .lambda
                  strings.trim-end:x:@.arguments/*/pattern
                     .:*
                  strings.starts-with:x:@.arguments/*/url
                     get-value:x:@strings.trim-end
                  return-value:x:@strings.starts-with
            if
               strings.ends-with:x:@.arguments/*/pattern
                  .:$
               .lambda
                  strings.trim-end:x:@.arguments/*/pattern
                     .:$
                  eq:x:@.arguments/*/url
                     get-value:x:@strings.trim-end
                  return-value:x:@eq
            strings.starts-with:x:@.arguments/*/url
               get-value:x:@.arguments/*/pattern
            return-value:x:@strings.starts-with
         .return
         .ignored:int:0
         while
            and
               mt:x:@.arguments/*/max
                  .:int:0
               exists:x:@sort/0
            .lambda
               .allowed:bool:true
               for-each:x:@.arguments/*/disallow/*
                  unwrap:x:+/*
                  invoke:x:@.match
                     url:x:@sort/0
                     pattern:x:@.dp/#
                  if
                     get-value:x:@invoke
                     .lambda
                        set-value:x:@.allowed
                           .:bool:false
                        for-each:x:@.arguments/*/allow/*
                           unwrap:x:+/*
                           invoke:x:@.match
                              url:x:@sort/0
                              pattern:x:@.dp/#
                           if
                              get-value:x:@invoke
                              .lambda
                                 set-value:x:@.allowed
                                    .:bool:true
               if
                  and
                     get-value:x:@.arguments/*/filter-on-url
                     exists:x:@.arguments/*/url
                     not-null:x:@.arguments/*/url
                     neq:x:@.arguments/*/url
                        .:
                     not
                        strings.starts-with:x:@sort/0
                           get-value:x:@.arguments/*/url
                  .lambda
                     set-value:x:@.allowed
                        .:bool:false
               if
                  eq:x:@.allowed
                     .:bool:true
                  .lambda
                     add:x:@.return
                        get-nodes:x:@sort/0
                     math.decrement:x:@.arguments/*/max
               else
                  math.increment:x:@.ignored
               remove-nodes:x:@sort/0
         if
            neq:x:@.ignored
               .:int:0
            .lambda
               strings.concat
                  get-value:x:@.ignored
                  .:" URLs disallowed by robots.txt or not matching base URL"
               unwrap:x:+/**
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:x:@strings.concat
                     type:warning
               sleep:100
         add:x:./*/return-nodes/*/urls
            get-nodes:x:@.return/*
         unwrap:x:+/*
         return-nodes
            has-sitemap:x:@.has-sitemap
            total:x:@.total
            urls
      .catch
         strings.concat
            .:"Something went wrong as we tried to load sitemap, error was; '"
            get-value:x:@.arguments/*/message
            .:"'"
         unwrap:x:+/**
         sockets.signal:x:@.arguments/@.arguments/*/feedback-channel
            roles:root
            args
               message:x:@strings.concat
               type:warning
         sleep:100
         return-nodes
            has-sitemap:bool:false
