
/*
 * This Hyperlambda code is designed to handle the invocation of AI functions within a session, ensuring that the number of invocations does not exceed a specified limit. It starts by checking if the current invocation contains a specific function call. If the number of invocations is too high, it logs an error and sends multiple error signals to the session. If the invocation is within limits, it executes the AI function, converts the result to JSON, and checks if the result size is manageable. Depending on the outcome, it updates the session with either a success message or logs an error if the execution fails. The code also constructs a new prompt based on the function's result or the success of the invocation.
 * 
 * 1. [if] - Checks if the current invocation contains a specific function call.
 * 2. [try] - Attempts to execute the AI function and handle potential errors.
 * 3. [if] - Checks if the number of invocations exceeds the limit.
 * 4. [log.error] - Logs an error message if too many invocations occur.
 * 5. [sockets.signal] - Sends error signals to the session if invocation limits are exceeded.
 * 6. [else] - Executes the AI function if invocation limits are not exceeded.
 * 7. [execute] - Invokes the AI function with specified parameters.
 * 8. [lambda2json] - Converts the function result to JSON format.
 * 9. [if] - Checks if the result size is within the allowed token limit.
 * 10. [throw] - Throws an error if the result size exceeds the limit.
 * 11. [config.get] - Retrieves a success message configuration.
 * 12. [unwrap] - Processes the result and configuration.
 * 13. [sockets.signal] - Sends the function result to the session.
 * 14. [if] - Checks if the function result exists.
 * 15. [set-value] - Updates the new prompt with the function result.
 * 16. [else] - Updates the new prompt with a success message if no result exists.
 * 17. [.catch] - Handles exceptions during AI function execution.
 * 18. [log.error] - Logs an error message if the AI function execution fails.
 * 19. [unwrap] - Processes the exception message.
 * 20. [sockets.signal] - Sends an error signal to the session with the exception message.
 * 21. [set-value] - Updates the new prompt with the exception message.
 */
if
   strings.contains:x:@.dp/#
      .:FUNCTION_INVOCATION[/
   .lambda
      try
         if
            lte:x:@.iterations
               .:int:1
            .lambda
               log.error:Too many function invocations
               sockets.signal:x:@.session
                  args
                     function_error:Too many function invocations
               sockets.signal:x:@.session
                  args
                     function_waiting:bool:false
               sockets.signal:x:@.session
                  args
                     error:bool:true
                     status:int:500
                     message:Too many function invocations. Configure your type to handle more invocations or change your prompt.
               sockets.signal:x:@.session
                  args
                     finished:bool:true
         else
            execute:magic.ai.functions.invoke
               type:x:@.type
               session:x:@.session
               user-id:x:@.user-id
               invocation:x:@.dp/#
               extra:x:@.extra
            lambda2json:x:@execute/*/result/*
               format:true
            if
               mt
                  openai.tokenize:x:@lambda2json
                  get-value:x:@.arguments/@.arguments/*/max_context_tokens
               .lambda
                  throw:Result too large, try to limit your result
                     status:int:400
                     public:bool:true
            config.get:"magic:chat:functions:success-message"
               .:Success!
            unwrap:x:+/*/*
            sockets.signal:x:@.session
               args
                  function_result:x:@config.get
                  invocation:x:@execute/*/json
                  file:x:@execute/*/workflow
            if
               exists:x:@execute/*/result/*
               .lambda
                  set-value:x:@.new-prompt
                     strings.concat
                        get-value:x:@.new-prompt
                        .:"Response from '"
                        get-value:x:@execute/*/workflow
                        .:@"' was:
```json
"
                        get-value:x:@lambda2json
                        .:@"
"
                        .:```
                        .:@"
"
                        .:@"
"
                  set-value:x:@.function-result
                     strings.concat
                        get-value:x:@.function-result
                        get-value:x:@lambda2json
                        .:"\n"
            else
               set-value:x:@.new-prompt
                  strings.concat
                     get-value:x:@.new-prompt
                     .:"Invocation of '"
                     get-value:x:@execute/*/workflow
                     .:"' was a success."
                     .:@"
"
                     .:@"
"
      .catch
         log.error:Could not execute AI function
            message:x:@.arguments/*/message
         unwrap:x:+/*/*
         sockets.signal:x:@.session
            args
               function_error:x:@.arguments/*/message
         set-value:x:@.new-prompt
            strings.concat
               get-value:x:@.new-prompt
               .:"Invocation failed, exception message was: '"
               get-value:x:@.arguments/*/message
               .:"'"
               .:@"
"
               .:@"
"
