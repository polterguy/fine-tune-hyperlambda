
/*
 * /*
 *  * This code checks if the [massagePrompt] argument is not null and not an empty string.
 *  * If the condition is true, it sets up an authorization token using a configuration value.
 *  * It then iterates over each child node of [tmp-snippets], making an HTTP POST request to OpenAI's chat completions endpoint for each snippet.
 *  * The request includes headers for authorization and content type, and a payload with model details and messages.
 *  * After each request, it checks if the HTTP status code is not in the 200-299 range.
 *  * If the status code indicates an error, it logs an error message with details from the response.
 *  * Otherwise, it updates the [prompt] node with the content from the response.
 *  *
 *  * 1. [if] - Checks if [massagePrompt] is not null and not an empty string.
 *  * 2. [and] - Combines conditions to check if [massagePrompt] is valid.
 *  * 3. [not-null] - Checks if [massagePrompt] is not null.
 *  * 4. [neq] - Checks if [massagePrompt] is not an empty string.
 *  * 5. [.lambda] - Executes the following nodes if the condition is true.
 *  * 6. [.token] - Declares a node for storing the token.
 *  * 7. [set-value] - Sets the value of [.token] to a concatenated string.
 *  * 8. [strings.concat] - Concatenates "Bearer " with the OpenAI API key.
 *  * 9. [for-each] - Iterates over each child node of [tmp-snippets].
 *  * 10. [http.post] - Makes an HTTP POST request to OpenAI's API.
 *  * 11. [convert] - Converts the response to a boolean.
 *  * 12. [headers] - Sets HTTP headers for the request.
 *  * 13. [Authorization] - Sets the authorization header with the token.
 *  * 14. [Content-Type] - Sets the content type to JSON.
 *  * 15. [Accept] - Sets the accept header to text/event-stream.
 *  * 16. [payload] - Specifies the payload for the HTTP request.
 *  * 17. [model] - Sets the model to "gpt-3.5-turbo".
 *  * 18. [max_tokens] - Sets the maximum number of tokens.
 *  * 19. [temperature] - Sets the temperature for the model.
 *  * 20. [messages] - Specifies the messages for the request.
 *  * 21. [role] - Sets the role for the system and user messages.
 *  * 22. [content] - Sets the content for the messages.
 *  * 23. [if] - Checks if the HTTP status code is not in the 200-299 range.
 *  * 24. [not] - Negates the condition.
 *  * 25. [and] - Combines conditions to check the status code.
 *  * 26. [mte] - Checks if the status code is more than or equal to 200.
 *  * 27. [lt] - Checks if the status code is less than 300.
 *  * 28. [.lambda] - Executes the following nodes if the condition is true.
 *  * 29. [lambda2hyper] - Converts the response to a Hyperlambda object.
 *  * 30. [log.error] - Logs an error message with details from the response.
 *  * 31. [message] - Logs the error message from the response.
 *  * 32. [status] - Logs the status code.
 *  * 33. [error] - Logs the error details.
 *  * 34. [else] - Executes the following nodes if the condition is false.
 *  * 35. [set-value] - Updates the [prompt] node with content from the response.
 *  * 36. [get-value] - Retrieves the content from the response.
 *  */
 */
if
   and
      not-null:x:@.arguments/*/massagePrompt
      neq:x:@.arguments/*/massagePrompt
         .:
   .lambda
      .token
      set-value:x:@.token
         strings.concat
            .:"Bearer "
            config.get:"magic:openai:key"
      for-each:x:@.tmp-snippets/*
         http.post:"https://api.openai.com/v1/chat/completions"
            convert:bool:true
            headers
               Authorization:x:@.token
               Content-Type:application/json
               Accept:text/event-stream
            payload
               model:gpt-3.5-turbo
               max_tokens:int:1000
               temperature:decimal:0.3
               messages
                  .
                     role:system
                     content:x:@.arguments/*/massagePrompt
                  .
                     role:user
                     content:x:@.dp/#/*/completion
         if
            not
               and
                  mte:x:@http.post
                     .:int:200
                  lt:x:@http.post
                     .:int:300
            .lambda
               lambda2hyper:x:@http.post
               log.error:Something went wrong while invoking OpenAI
                  message:x:@http.post/*/content/*/error/*/message
                  status:x:@http.post
                  error:x:@lambda2hyper
         else
            set-value:x:@.dp/#/*/prompt
               get-value:x:@http.post/*/content/*/choices/0/*/message/*/content
