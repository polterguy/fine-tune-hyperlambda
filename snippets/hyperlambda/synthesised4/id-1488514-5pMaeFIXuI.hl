
// Checks if [.result] contains both "___" and "FUNCTION_INVOCATION[", then splits [.result] by "___" and iterates through each part. For each part containing "FUNCTION_INVOCATION[", it tries to execute an AI function using [magic.ai.functions.invoke], serializes the result to JSON, checks token limits, and sends appropriate signals and messages to the session. If an error occurs during invocation, it logs the error, signals the session, and updates [.new-prompt] with the error message. After processing, it trims [.new-prompt].
if
   and
      strings.contains:x:@.result
         .:___
      strings.contains:x:@.result
         .:FUNCTION_INVOCATION[
   .lambda
      if
         eq:x:@.no-invocation
            .:int:0
         .lambda
            math.increment:x:@.no-invocation
      strings.split:x:@.result
         .:___
      for-each:x:@strings.split/*
         if
            strings.contains:x:@.dp/#
               .:FUNCTION_INVOCATION[/
            .lambda
               try
                  if
                     lte:x:@.iterations
                        .:int:1
                     .lambda
                        log.error:Too many function invocations
                        sockets.signal:x:@.session
                           args
                              function_error:Too many function invocations
                        sockets.signal:x:@.session
                           args
                              function_waiting:bool:false
                        sockets.signal:x:@.session
                           args
                              error:bool:true
                              status:int:500
                              message:Too many function invocations. Configure your type to handle more invocations or change your prompt.
                        sockets.signal:x:@.session
                           args
                              finished:bool:true
                  else
                     execute:magic.ai.functions.invoke
                        type:x:@.type
                        session:x:@.session
                        user-id:x:@.user-id
                        invocation:x:@.dp/#
                        extra:x:@.extra
                     lambda2json:x:@execute/*/result/*
                        format:true
                     if
                        mt
                           openai.tokenize:x:@lambda2json
                           get-value:x:@.arguments/@.arguments/*/max_context_tokens
                        .lambda
                           throw:Result too large, try to limit your result
                              status:int:400
                              public:bool:true
                     config.get:"magic:chat:functions:success-message"
                        .:Success!
                     unwrap:x:+/*/*
                     sockets.signal:x:@.session
                        args
                           function_result:x:@config.get
                           invocation:x:@execute/*/json
                           file:x:@execute/*/workflow
                     if
                        exists:x:@execute/*/result/*
                        .lambda
                           set-value:x:@.new-prompt
                              strings.concat
                                 get-value:x:@.new-prompt
                                 .:"Response from '"
                                 get-value:x:@execute/*/workflow
                                 .:@"' was:
```json
"
                                 get-value:x:@lambda2json
                                 .:@"
"
                                 .:```
                                 .:@"
"
                                 .:@"
"
                           set-value:x:@.function-result
                              strings.concat
                                 get-value:x:@.function-result
                                 get-value:x:@lambda2json
                                 .:"\n"
                     else
                        set-value:x:@.new-prompt
                           strings.concat
                              get-value:x:@.new-prompt
                              .:"Invocation of '"
                              get-value:x:@execute/*/workflow
                              .:"' was a success."
                              .:@"
"
                              .:@"
"
               .catch
                  log.error:Could not execute AI function
                     message:x:@.arguments/*/message
                  unwrap:x:+/*/*
                  sockets.signal:x:@.session
                     args
                        function_error:x:@.arguments/*/message
                  set-value:x:@.new-prompt
                     strings.concat
                        get-value:x:@.new-prompt
                        .:"Invocation failed, exception message was: '"
                        get-value:x:@.arguments/*/message
                        .:"'"
                        .:@"
"
                        .:@"
"
      set-value:x:@.new-prompt
         strings.trim:x:@.new-prompt
