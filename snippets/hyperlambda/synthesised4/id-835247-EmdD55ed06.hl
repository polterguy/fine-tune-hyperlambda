
/*
 * This Hyperlambda code iterates over each snippet node, concatenating its prompt and completion into a markdown format. It uses [strings.concat] to merge the prompt and completion with line breaks, then checks if the token count of the concatenated string is less than a specified maximum using [openai.tokenize] and [lt]. If true, it updates the markdown node with the concatenated string. 
 * 
 * 1. [for-each] - Iterates through each snippet node.
 * 2. [strings.concat] - Concatenates the prompt and completion with line breaks.
 * 3. [get-value] - Retrieves values of markdown, prompt, and completion nodes.
 * 4. [openai.tokenize] - Calculates the token count of the concatenated string.
 * 5. [lt] - Checks if the token count is less than max_tokens.
 * 6. [set-value] - Updates the markdown node with the concatenated string if the condition is true.
 */
for-each:x:@signal/0/*/snippets/*
   strings.concat
      get-value:x:@.markdown
      get-value:x:@.dp/#/*/prompt
      .:@"
"
      get-value:x:@.dp/#/*/completion
      .:@"
"
      .:@"
"
   if
      lt
         openai.tokenize:x:@strings.concat
         get-value:x:@.arguments/*/max_tokens
      .lambda
         set-value:x:@.markdown
            get-value:x:@strings.concat
