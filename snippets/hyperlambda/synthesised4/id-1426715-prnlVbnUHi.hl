
/*
 * This Hyperlambda code uses a [switch] statement to determine the model size based on the value of the [model] node. It evaluates different [case] conditions for various model names and adds a [model_size] node with a specific integer value to the [model] node depending on the matched case. The [add] slot is used to append the [model_size] node to the [model] node's children. The code handles multiple GPT model versions, assigning different model sizes to each. 
 * 
 * 1. [switch] - Evaluates the value of the [model] node to determine which [case] to execute.
 * 2. [case] - Specifies different model names to match against the [model] node's value.
 * 3. [add] - Appends a [model_size] node with a specific integer value to the [model] node's children when a [case] matches.
 * 4. [model_size] - Node added with an integer value representing the model size based on the matched [case].
 */
switch:x:@.model/*/model
   case:gpt-4o
   case:gpt-4o-mini
   case:gpt-4o-2024-05-13
   case:gpt-4-turbo
   case:gpt-4-0125-preview
   case:gpt-4-1106-preview
   case:gpt-4-turbo-preview
   case:gpt-4-turbo-2024-04-09
   case:gpt-4-vision-preview
   case:gpt-4-1106-vision-preview
      add:x:@.model
         .
            model_size:int:128000
   case:gpt-4
   case:gpt-4-0613
      add:x:@.model
         .
            model_size:int:8192
   case:gpt-4-32k
   case:gpt-4-32k-0613
      add:x:@.model
         .
            model_size:int:32768
   case:gpt-3.5-turbo
   case:gpt-3.5-turbo-0125
   case:gpt-3.5-turbo-1106
   case:gpt-3.5-turbo-16k
   case:gpt-3.5-turbo-16k-0613
      add:x:@.model
         .
            model_size:int:16384
   case:gpt-3.5-turbo-0613
   case:gpt-3.5-turbo-instruct
      add:x:@.model
         .
            model_size:int:4096
   case:o3-mini
      add:x:@.model
         .
            model_size:int:200000
   case:gpt-4.5-preview
      add:x:@.model
         .
            model_size:int:128000
