
// This Hyperlambda code iterates over each result node from a signal, performing a web scraping operation for each URL found, and signaling a session if specified. It uses [for-each] to iterate, [fork] to parallelize tasks, and [try] to handle exceptions. It adds session nodes and URL details to the current context and joins the results using [add] and [unwrap].
for-each:x:@signal/*/result/*
   .cur
      fork
         .reference
         try
            unwrap:x:+/*
            signal:magic.http.scrape-url
               url:x:@.reference/*/url
               semantics:bool:true
            if
               exists:x:@.reference/*/session
               .lambda
                  strings.concat
                     .:"Done scraping "
                     get-value:x:@.reference/*/url
                  unwrap:x:+/**
                  sockets.signal:x:@.reference/*/session
                     args
                        message:x:@strings.concat
                        type:system
         .catch
            log.error:Could not scrape URL
               url:x:@.reference/*/url
               message:x:@.arguments/*/message
   add:x:+/+/*
      get-nodes:x:@.arguments/*/session
   unwrap:x:+/*/*
   add:x:@.cur/*/fork/*/.reference
      .
         url:x:@.dp/#/*/url
         title:x:@.dp/#/*/title
   add:x:@.exe/*/join
      get-nodes:x:@.cur/*
