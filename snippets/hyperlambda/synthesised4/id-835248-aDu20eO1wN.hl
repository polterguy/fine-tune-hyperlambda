
/*
 * This Hyperlambda code checks if the [max_context_tokens] or [max_request_tokens] nodes are null, and if so, it uses a [switch] statement to determine the model type. For each model type, it calculates a value by subtracting half of [max_tokens] from a predefined integer, then divides the result by 2. This value is then set to both [max_context_tokens] and [max_request_tokens]. The [switch] statement handles various model cases, and a [default] case is provided for any unspecified models. 
 * 
 * 1. [if] - Checks if either [max_context_tokens] or [max_request_tokens] are null.
 * 2. [or] - Logical OR condition for null checks.
 * 3. [null] - Checks if a node is null.
 * 4. [switch] - Determines the model type and executes corresponding logic.
 * 5. [case] - Specifies different model types for conditional logic.
 * 6. [math.subtract] - Subtracts [max_tokens] from a predefined integer.
 * 7. [math.divide] - Divides the result of subtraction by 2.
 * 8. [set-value] - Sets the calculated value to [max_context_tokens] and [max_request_tokens].
 * 9. [default] - Handles unspecified model types with a default calculation.
 */
if
   or
      null:x:@.model/*/max_context_tokens
      null:x:@.model/*/max_request_tokens
   .lambda
      switch:x:@.model/*/model
         case:text-davinci-003
         case:gpt-3.5-turbo
         case:gpt-3.5-turbo-0301
         case:text-davinci-002
            math.divide
               math.subtract:int:4096
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         case:code-davinci-002
            math.divide
               math.subtract:int:8000
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         case:gpt-4
         case:gpt-4-0314
         case:gpt-4o
         case:gpt-4o-2024-05-13
            math.divide
               math.subtract:int:8192
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         case:gpt-3.5-turbo-0125
            math.divide
               math.subtract:int:16384
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         case:gpt-4-32k
         case:gpt-4-32k-0314
            math.divide
               math.subtract:int:32768
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         case:gpt-4-0125-preview
         case:gpt-4-1106-preview
            math.divide
               math.subtract:int:131072
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         case:o3-mini
            math.divide
               math.subtract:int:200000
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
         default
            math.divide
               math.subtract:int:2049
                  get-value:x:@.model/*/max_tokens
               .:int:2
            set-value:x:@.model/*/max_context_tokens
               get-value:x:@math.divide
            set-value:x:@.model/*/max_request_tokens
               get-value:x:@math.divide
