
// Checks if the current input contains a function invocation marker, and if so, attempts to execute an AI function by invoking "magic.ai.functions.invoke" with relevant arguments. If the number of function invocations exceeds a limit, it logs an error and sends error signals to the client. Otherwise, it serializes the function result to JSON, ensures the result does not exceed token limits, fetches a success message, and signals the client with the result. It also updates prompt variables with formatted responses. If an error occurs during execution, it logs the error, signals the client, and updates the prompt with the exception message.
if
   strings.contains:x:@.dp/#
      .:FUNCTION_INVOCATION[/
   .lambda
      try
         if
            lte:x:@.iterations
               .:int:1
            .lambda
               log.error:Too many function invocations
               sockets.signal:x:@.session
                  args
                     function_error:Too many function invocations
               sockets.signal:x:@.session
                  args
                     function_waiting:bool:false
               sockets.signal:x:@.session
                  args
                     error:bool:true
                     status:int:500
                     message:Too many function invocations. Configure your type to handle more invocations or change your prompt.
               sockets.signal:x:@.session
                  args
                     finished:bool:true
         else
            execute:magic.ai.functions.invoke
               type:x:@.type
               session:x:@.session
               user-id:x:@.user-id
               invocation:x:@.dp/#
               extra:x:@.extra
            lambda2json:x:@execute/*/result/*
               format:true
            if
               mt
                  openai.tokenize:x:@lambda2json
                  get-value:x:@.arguments/@.arguments/*/max_context_tokens
               .lambda
                  throw:Result too large, try to limit your result
                     status:int:400
                     public:bool:true
            config.get:"magic:chat:functions:success-message"
               .:Success!
            unwrap:x:+/*/*
            sockets.signal:x:@.session
               args
                  function_result:x:@config.get
                  invocation:x:@execute/*/json
                  file:x:@execute/*/workflow
            if
               exists:x:@execute/*/result/*
               .lambda
                  set-value:x:@.new-prompt
                     strings.concat
                        get-value:x:@.new-prompt
                        .:"Response from '"
                        get-value:x:@execute/*/workflow
                        .:@"' was:
```json
"
                        get-value:x:@lambda2json
                        .:@"
"
                        .:```
                        .:@"
"
                        .:@"
"
                  set-value:x:@.function-result
                     strings.concat
                        get-value:x:@.function-result
                        get-value:x:@lambda2json
                        .:"\n"
            else
               set-value:x:@.new-prompt
                  strings.concat
                     get-value:x:@.new-prompt
                     .:"Invocation of '"
                     get-value:x:@execute/*/workflow
                     .:"' was a success."
                     .:@"
"
                     .:@"
"
      .catch
         log.error:Could not execute AI function
            message:x:@.arguments/*/message
         unwrap:x:+/*/*
         sockets.signal:x:@.session
            args
               function_error:x:@.arguments/*/message
         set-value:x:@.new-prompt
            strings.concat
               get-value:x:@.new-prompt
               .:"Invocation failed, exception message was: '"
               get-value:x:@.arguments/*/message
               .:"'"
               .:@"
"
               .:@"
"
