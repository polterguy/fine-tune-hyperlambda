
/*
 * This Hyperlambda code snippet demonstrates how to make an HTTP POST request to the OpenAI API to generate a chat completion. It includes headers for authorization and content type, and sends a payload with model specifications, maximum token limit, temperature setting, and a message structure for system and user roles. The response is automatically converted to the appropriate type. 
 * 
 * 1. [http.post] - Sends an HTTP POST request to the specified URL.
 * 2. [headers] - Specifies HTTP headers for the request.
 * 3. [Authorization] - Sets the authorization token for API access.
 * 4. [Content-Type] - Sets the content type of the request to JSON.
 * 5. [payload] - Contains the data sent with the POST request.
 * 6. [model] - Specifies the AI model to be used.
 * 7. [max_tokens] - Sets the maximum number of tokens for the response.
 * 8. [temperature] - Sets the randomness of the response.
 * 9. [messages] - Contains the conversation context for the AI.
 * 10. [role] - Indicates the role of the message (system or user).
 * 11. [content] - Provides the content of the message.
 * 12. [convert] - Converts the response to the appropriate type.
 */
http.post:"https://api.openai.com/v1/chat/completions"
   headers
      Authorization:x:@.token
      Content-Type:application/json
   payload
      model:x:@.model
      max_tokens:x:@.max-size
      temperature:decimal:0.3
      messages
         .
            role:system
            content:Create a summary of the following information
         .
            role:user
            content:x:@.dp/#/*/completion
   convert:true
