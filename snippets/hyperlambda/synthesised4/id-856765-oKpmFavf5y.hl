
// This code snippet uses the [mt] slot to compare the number of tokens required for a given prompt, calculated by [openai.tokenize], against the maximum request tokens allowed for a model, converted to an integer using [convert]. If the prompt requires more tokens than the model's maximum, the [mt] slot will return true.
mt
   openai.tokenize:x:@.arguments/*/prompt
   convert:x:@.model/*/max_request_tokens
      type:int
