
/*
 * This Hyperlambda code sends a POST request to the OpenAI API to generate chat completions using the GPT-4o model. It includes headers for authorization and content type, and a payload specifying the model, maximum tokens, temperature, and a series of messages. The messages include roles and content, where the content is dynamically derived from arguments or context. The response is automatically converted to a lambda object. 
 * 
 * 1. [http.post] - Sends a POST request to the specified URL.
 * 2. [convert] - Indicates the response should be converted to a lambda object.
 * 3. [headers] - Specifies HTTP headers for the request.
 * 4. [Authorization] - Uses a token for authorization.
 * 5. [Content-Type] - Sets the content type to JSON.
 * 6. [payload] - Contains the data to be sent in the request body.
 * 7. [model] - Specifies the model to use, here "gpt-4o".
 * 8. [max_tokens] - Sets the maximum number of tokens for the response.
 * 9. [temperature] - Controls the randomness of the model's output.
 * 10. [messages] - Contains the conversation history for the model to generate a response.
 * 11. [role] - Defines the role of the message sender (system or user).
 * 12. [content] - Provides the message content, dynamically retrieved from arguments or context.
 */
http.post:"https://api.openai.com/v1/chat/completions"
   convert:bool:true
   headers
      Authorization:x:@.token
      Content-Type:application/json
   payload
      model:gpt-4o
      max_tokens:int:3600
      temperature:decimal:0.3
      messages
         .
            role:system
            content:x:@.arguments/*/instruction
         .
            role:user
            content:x:@.arguments/*/template
         .
            role:user
            content:x:@.context
