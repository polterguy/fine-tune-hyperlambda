
/*
 * The code snippet evaluates whether the number of tokens required for a JSON representation of a lambda object exceeds a specified maximum context token limit. It uses the [openai.tokenize] slot to determine the token count and the [mt] slot to compare it with the [max_context_tokens] value from the arguments. 
 * 
 * 1. [mt] - Compares two values to check if the first is more than the second.
 * 2. [openai.tokenize] - Calculates the number of tokens for the JSON representation of a lambda object.
 * 3. [get-value] - Retrieves the maximum context tokens value from the arguments.
 */
mt
   openai.tokenize:x:@lambda2json
   get-value:x:@.arguments/@.arguments/*/max_context_tokens
