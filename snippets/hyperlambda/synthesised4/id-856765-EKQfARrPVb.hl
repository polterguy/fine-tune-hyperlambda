
// This Hyperlambda code calculates and sets the maximum context and request tokens for a model. It first subtracts a specified number of tokens from the model's maximum tokens and divides the result by 2 using [math.divide]. The resulting value is then assigned to both [max_context_tokens] and [max_request_tokens] using [set-value]. The code ensures that the model's token limits are appropriately adjusted based on the initial maximum tokens.
case:gpt-4o-2024-05-13
   math.divide
      math.subtract:int:8192
         get-value:x:@.model/*/max_tokens
      .:int:2
   set-value:x:@.model/*/max_context_tokens
      get-value:x:@math.divide
   set-value:x:@.model/*/max_request_tokens
      get-value:x:@math.divide
