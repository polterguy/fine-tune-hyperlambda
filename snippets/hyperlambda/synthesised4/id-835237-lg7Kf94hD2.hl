
// This Hyperlambda code snippet demonstrates how to use the OpenAI Whisper API to transcribe audio content. It retrieves an API key using [config.get], specifies the media type and language from the arguments, and reads the audio content using [io.stream.read]. The slots used are: [openai.whisper] for transcription, [key] to get the API key, [type] and [language] to specify media type and language, and [content] to read the audio stream.
openai.whisper
   key:x:@config.get
   type:x:@.arguments/*/mediaType
   language:x:@.arguments/*/language
   content:x:@io.stream.read
