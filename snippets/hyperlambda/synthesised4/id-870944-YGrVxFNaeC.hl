
/*
 * This Hyperlambda code iterates over each [result] node under [signal], creating a [fork] for each iteration to scrape a URL and optionally signal a session with the scraped data. It uses [try] to handle potential errors during the scraping process, logging errors if they occur. The code also adds session nodes and unwraps and adds references to URLs and titles, finally joining the results into an [exe] node. 
 * 
 * 1. [for-each] - Iterates over each [result] node under [signal].
 * 2. [.cur] - Creates a temporary node for the current iteration.
 * 3. [fork] - Initiates a parallel execution for scraping.
 * 4. [.reference] - Holds reference data for the current URL and session.
 * 5. [try] - Attempts to scrape the URL and signal a session.
 * 6. [unwrap] - Evaluates expressions for the current fork.
 * 7. [signal] - Sends a signal to scrape the URL.
 * 8. [if] - Checks if a session exists to send a message.
 * 9. [strings.concat] - Concatenates strings for the message.
 * 10. [sockets.signal] - Sends a signal with the message to the session.
 * 11. [.catch] - Logs an error if scraping fails.
 * 12. [log.error] - Logs the error message and URL.
 * 13. [add] - Adds session nodes and references to the current fork.
 * 14. [get-nodes] - Retrieves nodes for session and reference data.
 * 15. [unwrap] - Further evaluates expressions.
 * 16. [add] - Adds URL and title references to the current fork.
 * 17. [add] - Joins the results into an [exe] node.
 */
for-each:x:@signal/*/result/*
   .cur
      fork
         .reference
         try
            unwrap:x:+/*
            signal:magic.http.scrape-url
               url:x:@.reference/*/url
               semantics:bool:true
            if
               exists:x:@.reference/*/session
               .lambda
                  strings.concat
                     .:"Done scraping "
                     get-value:x:@.reference/*/url
                  unwrap:x:+/**
                  sockets.signal:x:@.reference/*/session
                     args
                        message:x:@strings.concat
                        type:system
         .catch
            log.error:Could not scrape URL
               url:x:@.reference/*/url
               message:x:@.arguments/*/message
   add:x:+/+/*
      get-nodes:x:@.arguments/*/session
   unwrap:x:+/*/*
   add:x:@.cur/*/fork/*/.reference
      .
         url:x:@.dp/#/*/url
         title:x:@.dp/#/*/title
   add:x:@.exe/*/join
      get-nodes:x:@.cur/*
