
// The `openai.tokenize` slot calculates and returns the number of tokens required for the text specified by the expression `@.context`, which points to a node named `.context`. This is useful for determining token usage in OpenAI endpoints.
openai.tokenize:x:@.context
