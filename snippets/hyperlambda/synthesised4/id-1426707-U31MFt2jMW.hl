
/*
 * This Hyperlambda code iterates over each child node of the [signal] node and sends an HTTP POST request to the OpenAI API to generate chat completions. It uses the [http.post] slot with headers for authorization and content type, and a payload specifying the model, max tokens, temperature, and messages. If the response status code is not between 200 and 299, it logs an error message. Otherwise, it updates the [prompt] node with the content of the generated message from the API response.
 * 
 * 1. [for-each] - Iterates over each child node of the [signal] node.
 * 2. [http.post] - Sends an HTTP POST request to the OpenAI API.
 * 3. [convert] - Converts the response to a lambda object.
 * 4. [headers] - Sets the authorization and content type headers for the request.
 * 5. [payload] - Specifies the model, max tokens, temperature, and messages for the API request.
 * 6. [if] - Checks if the response status code is not between 200 and 299.
 * 7. [not] - Inverts the condition.
 * 8. [and] - Combines multiple conditions.
 * 9. [mte] - Checks if the status code is more than or equal to 200.
 * 10. [lt] - Checks if the status code is less than 300.
 * 11. [.lambda] - Executes the error handling code if the condition is true.
 * 12. [lambda2hyper] - Converts the response to a Hyperlambda object.
 * 13. [log.error] - Logs an error message if the API request fails.
 * 14. [else] - Executes the code to update the [prompt] node if the API request is successful.
 * 15. [set-value] - Updates the [prompt] node with the content of the generated message.
 * 16. [get-value] - Retrieves the content of the generated message from the API response.
 */
for-each:x:@signal/*
   http.post:"https://api.openai.com/v1/chat/completions"
      convert:bool:true
      headers
         Authorization:x:@.token
         Content-Type:application/json
         Accept:text/event-stream
      payload
         model:gpt-3.5-turbo
         max_tokens:int:1000
         temperature:decimal:0.3
         messages
            .
               role:system
               content:x:@.arguments/*/massagePrompt
            .
               role:user
               content:x:@.dp/#/*/completion
   if
      not
         and
            mte:x:@http.post
               .:int:200
            lt:x:@http.post
               .:int:300
      .lambda
         lambda2hyper:x:@http.post
         log.error:Something went wrong while invoking OpenAI
            message:x:@http.post/*/content/*/error/*/message
            status:x:@http.post
            error:x:@lambda2hyper
   else
      set-value:x:@.dp/#/*/prompt
         get-value:x:@http.post/*/content/*/choices/0/*/message/*/content
