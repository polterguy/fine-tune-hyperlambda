
/*
 * This Hyperlambda code iterates over each node resulting from splitting a string using [strings.split], checking if each node contains the substring "FUNCTION_INVOCATION[/". If true, it attempts to execute an AI function using [magic.ai.functions.invoke], handling errors and signaling the session with results or errors. It logs errors if too many invocations occur, and constructs a new prompt or function result based on the execution outcome. The code ensures the result is within token limits and handles exceptions by logging and signaling errors.
 * 
 * 1. [for-each] - Iterates over each node from the result of [strings.split].
 * 2. [if] - Checks if the current node contains "FUNCTION_INVOCATION[/".
 * 3. [try] - Attempts to execute the AI function and handle errors.
 * 4. [if] - Checks if the number of iterations is less than or equal to 1.
 * 5. [log.error] - Logs an error if too many function invocations occur.
 * 6. [sockets.signal] - Signals the session with various error messages.
 * 7. [else] - Executes the AI function if the condition is false.
 * 8. [execute] - Invokes the AI function with specified arguments.
 * 9. [lambda2json] - Converts the execution result to JSON format.
 * 10. [if] - Checks if the result exceeds the maximum token limit.
 * 11. [throw] - Throws an error if the result is too large.
 * 12. [config.get] - Retrieves a success message from the configuration.
 * 13. [unwrap] - Unwraps the configuration result.
 * 14. [sockets.signal] - Signals the session with the function result.
 * 15. [if] - Checks if the execution result exists.
 * 16. [set-value] - Sets the new prompt with the execution result.
 * 17. [strings.concat] - Concatenates strings to form the new prompt.
 * 18. [else] - Sets the new prompt if the execution was successful.
 * 19. [.catch] - Handles exceptions during execution.
 * 20. [log.error] - Logs an error if the AI function execution fails.
 * 21. [unwrap] - Unwraps the exception message.
 * 22. [sockets.signal] - Signals the session with the error message.
 * 23. [set-value] - Sets the new prompt with the exception message.
 * 24. [strings.concat] - Concatenates strings to form the new prompt.
 */
for-each:x:@strings.split/*
   if
      strings.contains:x:@.dp/#
         .:FUNCTION_INVOCATION[/
      .lambda
         try
            if
               lte:x:@.iterations
                  .:int:1
               .lambda
                  log.error:Too many function invocations
                  sockets.signal:x:@.session
                     args
                        function_error:Too many function invocations
                  sockets.signal:x:@.session
                     args
                        function_waiting:bool:false
                  sockets.signal:x:@.session
                     args
                        error:bool:true
                        status:int:500
                        message:Too many function invocations. Configure your type to handle more invocations or change your prompt.
                  sockets.signal:x:@.session
                     args
                        finished:bool:true
            else
               execute:magic.ai.functions.invoke
                  type:x:@.type
                  session:x:@.session
                  user-id:x:@.user-id
                  invocation:x:@.dp/#
                  extra:x:@.extra
               lambda2json:x:@execute/*/result/*
                  format:true
               if
                  mt
                     openai.tokenize:x:@lambda2json
                     get-value:x:@.arguments/@.arguments/*/max_context_tokens
                  .lambda
                     throw:Result too large, try to limit your result
                        status:int:400
                        public:bool:true
               config.get:"magic:chat:functions:success-message"
                  .:Success!
               unwrap:x:+/*/*
               sockets.signal:x:@.session
                  args
                     function_result:x:@config.get
                     invocation:x:@execute/*/json
                     file:x:@execute/*/workflow
               if
                  exists:x:@execute/*/result/*
                  .lambda
                     set-value:x:@.new-prompt
                        strings.concat
                           get-value:x:@.new-prompt
                           .:"Response from '"
                           get-value:x:@execute/*/workflow
                           .:@"' was:
```json
"
                           get-value:x:@lambda2json
                           .:@"
"
                           .:```
                           .:@"
"
                           .:@"
"
                     set-value:x:@.function-result
                        strings.concat
                           get-value:x:@.function-result
                           get-value:x:@lambda2json
                           .:"\n"
               else
                  set-value:x:@.new-prompt
                     strings.concat
                        get-value:x:@.new-prompt
                        .:"Invocation of '"
                        get-value:x:@execute/*/workflow
                        .:"' was a success."
                        .:@"
"
                        .:@"
"
         .catch
            log.error:Could not execute AI function
               message:x:@.arguments/*/message
            unwrap:x:+/*/*
            sockets.signal:x:@.session
               args
                  function_error:x:@.arguments/*/message
            set-value:x:@.new-prompt
               strings.concat
                  get-value:x:@.new-prompt
                  .:"Invocation failed, exception message was: '"
                  get-value:x:@.arguments/*/message
                  .:"'"
                  .:@"
"
                  .:@"
"
