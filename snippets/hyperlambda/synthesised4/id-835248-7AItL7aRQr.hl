
// This Hyperlambda code uses a [switch] statement to determine the model type from the [.model] node and sets the [max_context_tokens] and [max_request_tokens] based on predefined conditions for each model. For specific models, it calculates these values by subtracting the [max_tokens] from a constant, divides the result by 2, and assigns it to both [max_context_tokens] and [max_request_tokens]. If the model doesn't match any [case], a default calculation is applied.
switch:x:@.model/*/model
   case:text-davinci-003
   case:gpt-3.5-turbo
   case:gpt-3.5-turbo-0301
   case:text-davinci-002
      math.divide
         math.subtract:int:4096
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   case:code-davinci-002
      math.divide
         math.subtract:int:8000
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   case:gpt-4
   case:gpt-4-0314
   case:gpt-4o
   case:gpt-4o-2024-05-13
      math.divide
         math.subtract:int:8192
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   case:gpt-3.5-turbo-0125
      math.divide
         math.subtract:int:16384
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   case:gpt-4-32k
   case:gpt-4-32k-0314
      math.divide
         math.subtract:int:32768
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   case:gpt-4-0125-preview
   case:gpt-4-1106-preview
      math.divide
         math.subtract:int:131072
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   case:o3-mini
      math.divide
         math.subtract:int:200000
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
   default
      math.divide
         math.subtract:int:2049
            get-value:x:@.model/*/max_tokens
         .:int:2
      set-value:x:@.model/*/max_context_tokens
         get-value:x:@math.divide
      set-value:x:@.model/*/max_request_tokens
         get-value:x:@math.divide
