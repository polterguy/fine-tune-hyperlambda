
/*
 * This Hyperlambda code defines a dynamic slot [magic.ai.load-sitemap] that recursively loads and processes sitemaps from given URLs. It validates input arguments, retrieves sitemaps, parses XML content, and collects URLs up to a specified maximum. The slot supports handling headers, feedback channels, and filtering URLs based on patterns. It also manages errors and signals warnings if issues occur during sitemap retrieval. The code is useful for web crawling or indexing tasks, ensuring efficient sitemap processing and URL collection.
 * 
 * 1. [slots.create] - Creates a dynamic slot named "magic.ai.load-sitemap".
 * 2. [validators.mandatory] - Ensures the presence of required sitemap arguments.
 * 3. [validators.integer] - Validates the "max" argument as an integer within a specified range.
 * 4. [validators.default] - Sets default values for arguments if not provided.
 * 5. [if] - Checks if headers exist, adds default headers if not.
 * 6. [.urls] - Initializes a node to store collected URLs.
 * 7. [.has-sitemap] - Boolean flag indicating if a sitemap was successfully retrieved.
 * 8. [try] - Attempts to retrieve and process sitemaps.
 * 9. [for-each] - Iterates over sitemap URLs to retrieve and process each one.
 * 10. [strings.concat] - Concatenates strings for logging and signaling.
 * 11. [unwrap] - Evaluates expressions and signals feedback.
 * 12. [sockets.signal] - Sends feedback messages through a specified channel.
 * 13. [sleep] - Pauses execution for a specified time.
 * 14. [lt] - Checks if the number of URLs is less than a specified limit.
 * 15. [.domain] - Extracts domain information from URLs.
 * 16. [strings.split] - Splits strings based on a delimiter.
 * 17. [set-value] - Sets the value of a node.
 * 18. [add] - Adds nodes or values to a specified location.
 * 19. [http.get] - Performs HTTP GET requests to retrieve sitemap content.
 * 20. [log.error] - Logs error messages if sitemap retrieval fails.
 * 21. [throw] - Throws exceptions for error handling.
 * 22. [not-exists] - Checks if a node does not exist.
 * 23. [or] - Logical OR operation for conditions.
 * 24. [strings.starts-with] - Checks if a string starts with a specified prefix.
 * 25. [strings.trim] - Trims whitespace from strings.
 * 26. [xml2lambda] - Converts XML content to a lambda structure.
 * 27. [for-each] - Iterates over XML nodes to extract URLs.
 * 28. [not] - Logical NOT operation for conditions.
 * 29. [strings.concat] - Concatenates strings for URL construction.
 * 30. [not-exists] - Checks if a URL does not already exist in the list.
 * 31. [unwrap] - Evaluates expressions and processes nested nodes.
 * 32. [signal] - Invokes the same slot recursively for nested sitemaps.
 * 33. [sort] - Sorts URLs based on length.
 * 34. [strings.length] - Retrieves the length of a string.
 * 35. [.match] - Matches URLs against patterns.
 * 36. [strings.ends-with] - Checks if a string ends with a specified suffix.
 * 37. [strings.trim-end] - Trims the end of a string.
 * 38. [eq] - Checks if two values are equal.
 * 39. [return-value] - Returns a boolean result from a condition.
 * 40. [.return] - Stores URLs to be returned.
 * 41. [.ignored] - Counts URLs ignored due to disallow rules.
 * 42. [while] - Loops while conditions are met.
 * 43. [.allowed] - Boolean flag indicating if a URL is allowed.
 * 44. [invoke] - Invokes a match check for URL patterns.
 * 45. [get-value] - Retrieves the value of a node.
 * 46. [exists] - Checks if a node exists.
 * 47. [not-null] - Checks if a node is not null.
 * 48. [neq] - Checks if two values are not equal.
 * 49. [math.decrement] - Decreases the "max" argument value.
 * 50. [math.increment] - Increases the "ignored" count.
 * 51. [remove-nodes] - Removes nodes from a list.
 * 52. [if] - Checks if any URLs were ignored and signals warnings.
 * 53. [add] - Adds URLs to the return list.
 * 54. [unwrap] - Evaluates expressions and processes nested nodes.
 * 55. [return-nodes] - Returns the collected URLs and sitemap status.
 * 56. [.catch] - Handles exceptions and signals warnings.
 * 57. [strings.concat] - Concatenates error messages.
 * 58. [sockets.signal] - Sends error messages through a feedback channel.
 * 59. [sleep] - Pauses execution for a specified time.
 * 60. [return-nodes] - Returns the sitemap status as false in case of errors.
 */
slots.create:magic.ai.load-sitemap
   validators.mandatory:x:@.arguments/*/sitemap/*/[0,1]
   validators.integer:x:@.arguments/*/max
      min:1
      max:10000
   validators.default:x:@.arguments
      max:int:25
   if
      not-exists:x:@.arguments/*/headers
      .lambda
         add:x:@.arguments
            .
               headers
   validators.default:x:@.arguments/*/headers
      User-Agent:AINIRO-Crawler 2.0
      Accept-Encoding:identity
      Accept:text/xml
   .urls
   .has-sitemap:bool:false
   try
      for-each:x:@.arguments/*/sitemap/*/[0,25]
         strings.concat
            .:"Retrieving sitemap "
            get-value:x:@.dp/#
         unwrap:x:+/**
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:x:@strings.concat
               type:info
         sleep:100
         if
            lt
               get-count:x:@.urls/*
               .:int:10000
            .lambda
               .domain
               strings.split:x:@.dp/#
                  .:/
               set-value:x:@.domain
                  strings.concat
                     get-value:x:@strings.split/0
                     .://
                     get-value:x:@strings.split/1
               add:x:./*/http.get
                  get-nodes:x:@.arguments/*/headers
               http.get:x:@.dp/#
                  timeout:60
               if
                  and
                     not
                        mte:x:@http.get
                           .:int:200
                     not
                        lt:x:@http.get
                           .:int:300
                  .lambda
                     log.error:Sitemap invocation did not return success status
                        url:x:@.dp/#
                        status:x:@http.get
                     throw:Could not retrieve sitemap
               if
                  not
                     or
                        strings.starts-with:x:@http.get/*/headers/*/Content-Type
                           .:application/xml
                        strings.starts-with:x:@http.get/*/headers/*/content-type
                           .:application/xml
                        strings.starts-with:x:@http.get/*/headers/*/Content-Type
                           .:text/xml
                        strings.starts-with:x:@http.get/*/headers/*/content-type
                           .:text/xml
                  .lambda
                     throw:Sitemap was not XML
               else
                  set-value:x:@.has-sitemap
                     .:bool:true
                  strings.trim:x:@http.get/*/content
                  xml2lambda:x:@strings.trim
                  for-each:x:"@xml2lambda/*/urlset/*/url/*/loc/*/\\#text"
                     if
                        lt
                           get-count:x:@.urls/*
                           .:int:10000
                        .lambda
                           .url
                           set-value:x:@.url
                              get-value:x:@.dp/#
                           if
                              and
                                 not
                                    strings.starts-with:x:@.dp/#
                                       .:"http://"
                                 not
                                    strings.starts-with:x:@.dp/#
                                       .:"https://"
                              .lambda
                                 set-value:x:@.url
                                    strings.concat
                                       get-value:x:@.domain
                                       get-value:x:@.dp/#
                           if
                              not-exists:x:@.urls/*/={@.url}
                              .lambda
                                 unwrap:x:+/*/*
                                 add:x:@.urls
                                    .
                                       .:x:@.url
                  for-each:x:"@xml2lambda/*/urlset/*/url/*/loc/*/\\#cdata-section"
                     if
                        lt
                           get-count:x:@.urls/*
                           .:int:10000
                        .lambda
                           .url
                           set-value:x:@.url
                              get-value:x:@.dp/#
                           if
                              and
                                 not
                                    strings.starts-with:x:@.dp/#
                                       .:"http://"
                                 not
                                    strings.starts-with:x:@.dp/#
                                       .:"https://"
                              .lambda
                                 set-value:x:@.url
                                    strings.concat
                                       get-value:x:@.domain
                                       get-value:x:@.dp/#
                           if
                              not-exists:x:@.urls/*/={@.url}
                              .lambda
                                 unwrap:x:+/*/*
                                 add:x:@.urls
                                    .
                                       .:x:@.url
                  for-each:x:"@xml2lambda/*/sitemapindex/*/sitemap/*/[0,25]/loc/*/\\#cdata-section"
                     if
                        lt
                           get-count:x:@.urls/*
                           .:int:10000
                        .lambda
                           add:x:./*/signal
                              get-nodes:x:@.arguments/*/headers
                           unwrap:x:+/**
                           signal:magic.ai.load-sitemap
                              max:int:10000
                              feedback-channel:x:@.arguments/*/feedback-channel
                              filter-on-url:x:@.arguments/*/filter-on-url
                              sitemap
                                 .:x:@.dp/#
                           add:x:@.urls
                              get-nodes:x:@signal/*/urls/*
                           if
                              and
                                 eq:x:@signal/*/has-sitemap
                                    .:bool:false
                                 eq
                                    get-count:x:@.urls/*
                                    .:int:0
                              .lambda
                                 set-value:x:@.has-sitemap
                                    .:bool:false
                  for-each:x:"@xml2lambda/*/sitemapindex/*/sitemap/*/[0,25]/loc/*/\\#text"
                     if
                        lt
                           get-count:x:@.urls/*
                           .:int:10000
                        .lambda
                           unwrap:x:+/**
                           signal:magic.ai.load-sitemap
                              max:int:10000
                              feedback-channel:x:@.arguments/*/feedback-channel
                              filter-on-url:x:@.arguments/*/filter-on-url
                              sitemap
                                 .:x:@.dp/#
                           add:x:@.urls
                              get-nodes:x:@signal/*/urls/*
                           if
                              and
                                 eq:x:@signal/*/has-sitemap
                                    .:bool:false
                                 eq
                                    get-count:x:@.urls/*
                                    .:int:0
                              .lambda
                                 set-value:x:@.has-sitemap
                                    .:bool:false
      .total
      set-value:x:@.total
         get-count:x:@.urls/*
      sort:x:@.urls/*
         if
            lt
               strings.length:x:@.lhs/#
               strings.length:x:@.rhs/#
            .lambda
               set-value:x:@.result
                  .:int:-1
         else-if
            mt
               strings.length:x:@.lhs/#
               strings.length:x:@.rhs/#
            .lambda
               set-value:x:@.result
                  .:int:1
         else
            set-value:x:@.result
               .:int:0
      .match
         if
            strings.ends-with:x:@.arguments/*/pattern
               .:*
            .lambda
               strings.trim-end:x:@.arguments/*/pattern
                  .:*
               strings.starts-with:x:@.arguments/*/url
                  get-value:x:@strings.trim-end
               return-value:x:@strings.starts-with
         if
            strings.ends-with:x:@.arguments/*/pattern
               .:$
            .lambda
               strings.trim-end:x:@.arguments/*/pattern
                  .:$
               eq:x:@.arguments/*/url
                  get-value:x:@strings.trim-end
               return-value:x:@eq
         strings.starts-with:x:@.arguments/*/url
            get-value:x:@.arguments/*/pattern
         return-value:x:@strings.starts-with
      .return
      .ignored:int:0
      while
         and
            mt:x:@.arguments/*/max
               .:int:0
            exists:x:@sort/0
         .lambda
            .allowed:bool:true
            for-each:x:@.arguments/*/disallow/*
               unwrap:x:+/*
               invoke:x:@.match
                  url:x:@sort/0
                  pattern:x:@.dp/#
               if
                  get-value:x:@invoke
                  .lambda
                     set-value:x:@.allowed
                        .:bool:false
                     for-each:x:@.arguments/*/allow/*
                        unwrap:x:+/*
                        invoke:x:@.match
                           url:x:@sort/0
                           pattern:x:@.dp/#
                        if
                           get-value:x:@invoke
                           .lambda
                              set-value:x:@.allowed
                                 .:bool:true
            if
               and
                  get-value:x:@.arguments/*/filter-on-url
                  exists:x:@.arguments/*/url
                  not-null:x:@.arguments/*/url
                  neq:x:@.arguments/*/url
                     .:
                  not
                     strings.starts-with:x:@sort/0
                        get-value:x:@.arguments/*/url
               .lambda
                  set-value:x:@.allowed
                     .:bool:false
            if
               eq:x:@.allowed
                  .:bool:true
               .lambda
                  add:x:@.return
                     get-nodes:x:@sort/0
                  math.decrement:x:@.arguments/*/max
            else
               math.increment:x:@.ignored
            remove-nodes:x:@sort/0
      if
         neq:x:@.ignored
            .:int:0
         .lambda
            strings.concat
               get-value:x:@.ignored
               .:" URLs disallowed by robots.txt or not matching base URL"
            unwrap:x:+/**
            sockets.signal:x:@.arguments/*/feedback-channel
               args
                  message:x:@strings.concat
                  type:warning
            sleep:100
      add:x:./*/return-nodes/*/urls
         get-nodes:x:@.return/*
      unwrap:x:+/*
      return-nodes
         has-sitemap:x:@.has-sitemap
         total:x:@.total
         urls
   .catch
      strings.concat
         .:"Something went wrong as we tried to load sitemap, error was; '"
         get-value:x:@.arguments/*/message
         .:"'"
      unwrap:x:+/**
      sockets.signal:x:@.arguments/@.arguments/*/feedback-channel
         roles:root
         args
            message:x:@strings.concat
            type:warning
      sleep:100
      return-nodes
         has-sitemap:bool:false
