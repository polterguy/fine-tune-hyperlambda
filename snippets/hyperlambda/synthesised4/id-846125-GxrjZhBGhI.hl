
// This Hyperlambda code handles the execution of a function and processes its result. It uses [execute] to invoke a function and [lambda2json] to convert the result to JSON. The [if] condition checks if the token count exceeds a maximum limit, throwing an error if true. It retrieves a success message with [config.get] and signals the result via [sockets.signal]. If a result exists, it updates [.new-prompt] and [.function-result] with the response details; otherwise, it logs a success message.
else
   execute:magic.ai.functions.invoke
      type:x:@.type
      session:x:@.session
      user-id:x:@.user-id
      invocation:x:@.dp/#
      extra:x:@.extra
   lambda2json:x:@execute/*/result/*
      format:true
   if
      mt
         openai.tokenize:x:@lambda2json
         get-value:x:@.arguments/@.arguments/*/max_context_tokens
      .lambda
         throw:Result too large, try to limit your result
            status:int:400
            public:bool:true
   config.get:"magic:chat:functions:success-message"
      .:Success!
   unwrap:x:+/*/*
   sockets.signal:x:@.session
      args
         function_result:x:@config.get
         invocation:x:@execute/*/json
         file:x:@execute/*/workflow
   if
      exists:x:@execute/*/result/*
      .lambda
         set-value:x:@.new-prompt
            strings.concat
               get-value:x:@.new-prompt
               .:"Response from '"
               get-value:x:@execute/*/workflow
               .:@"' was:
```json
"
               get-value:x:@lambda2json
               .:@"
"
               .:```
               .:@"
"
               .:@"
"
         set-value:x:@.function-result
            strings.concat
               get-value:x:@.function-result
               get-value:x:@lambda2json
               .:"\n"
   else
      set-value:x:@.new-prompt
         strings.concat
            get-value:x:@.new-prompt
            .:"Invocation of '"
            get-value:x:@execute/*/workflow
            .:"' was a success."
            .:@"
"
            .:@"
"
