
// If the previous condition is false, this code executes a function invocation, converts its result to formatted JSON, checks if the token count exceeds a maximum and throws an error if it does, retrieves a success message, sends a socket signal with the result, and updates prompt and function result values based on whether the invocation produced a result or not.
else
   execute:magic.ai.functions.invoke
      type:x:@.type
      session:x:@.session
      user-id:x:@.user-id
      invocation:x:@.dp/#
      extra:x:@.extra
   lambda2json:x:@execute/*/result/*
      format:true
   if
      mt
         openai.tokenize:x:@lambda2json
         get-value:x:@.arguments/@.arguments/*/max_context_tokens
      .lambda
         throw:Result too large, try to limit your result
            status:int:400
            public:bool:true
   config.get:"magic:chat:functions:success-message"
      .:Success!
   unwrap:x:+/*/*
   sockets.signal:x:@.session
      args
         function_result:x:@config.get
         invocation:x:@execute/*/json
         file:x:@execute/*/workflow
   if
      exists:x:@execute/*/result/*
      .lambda
         set-value:x:@.new-prompt
            strings.concat
               get-value:x:@.new-prompt
               .:"Response from '"
               get-value:x:@execute/*/workflow
               .:@"' was:
```json
"
               get-value:x:@lambda2json
               .:@"
"
               .:```
               .:@"
"
               .:@"
"
         set-value:x:@.function-result
            strings.concat
               get-value:x:@.function-result
               get-value:x:@lambda2json
               .:"\n"
   else
      set-value:x:@.new-prompt
         strings.concat
            get-value:x:@.new-prompt
            .:"Invocation of '"
            get-value:x:@execute/*/workflow
            .:"' was a success."
            .:@"
"
            .:@"
"
