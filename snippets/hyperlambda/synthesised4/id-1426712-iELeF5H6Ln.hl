
/*
 * This Hyperlambda code checks if the number of tokens required for a given input exceeds a specified maximum context token limit. If the token count is greater than the allowed limit, it throws an exception with a status code of 400 and a public message indicating that the result is too large and should be limited. 
 * 
 * 1. [if] - Initiates a conditional statement.
 * 2. [mt] - Compares if the first argument is more than the second argument.
 * 3. [openai.tokenize] - Calculates the number of tokens for the input.
 * 4. [get-value] - Retrieves the maximum context tokens allowed from the arguments.
 * 5. [.lambda] - Executes the following code block if the condition is true.
 * 6. [throw] - Raises an exception with a custom message and status code.
 * 7. [status] - Sets the HTTP status code for the exception.
 * 8. [public] - Indicates if the exception message should be publicly visible.
 */
if
   mt
      openai.tokenize:x:@lambda2json
      get-value:x:@.arguments/@.arguments/*/max_context_tokens
   .lambda
      throw:Result too large, try to limit your result
         status:int:400
         public:bool:true
