
/*
 * This Hyperlambda code calculates the maximum context and request tokens for a model by first subtracting the value of the [max_tokens] node from 8192, dividing the result by 2, and then setting the [max_context_tokens] and [max_request_tokens] nodes to this calculated value. The code ensures that both the context and request tokens are evenly distributed based on the model's maximum token capacity.
 * 
 * 1. [math.subtract] - Subtracts the value of [max_tokens] from 8192.
 * 2. [math.divide] - Divides the result of the subtraction by 2.
 * 3. [set-value] - Sets the value of [max_context_tokens] to the result of the division.
 * 4. [set-value] - Sets the value of [max_request_tokens] to the result of the division.
 */
case:gpt-4o-2024-05-13
   math.divide
      math.subtract:int:8192
         get-value:x:@.model/*/max_tokens
      .:int:2
   set-value:x:@.model/*/max_context_tokens
      get-value:x:@math.divide
   set-value:x:@.model/*/max_request_tokens
      get-value:x:@math.divide
