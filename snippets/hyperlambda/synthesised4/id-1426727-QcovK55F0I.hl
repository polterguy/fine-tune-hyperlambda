
// This Hyperlambda code creates a dynamic slot named [magic.ai.crawl-site-on-thread] that crawls a website to gather URLs and generate OpenAI training data. It first checks for a robots.txt file and sitemaps, sending feedback messages through a specified channel. If sitemaps are found, it retrieves URLs and scrapes them, logging progress and handling errors. If no sitemaps are found, it attempts to crawl the site directly. The code also manages delays to avoid server overload and executes a callback function if provided.
slots.create:magic.ai.crawl-site-on-thread
   validators.default:x:@.arguments
      summarize:bool:true
   unwrap:x:+/*
   signal:magic.ai.load-robots
      url:x:@.arguments/*/url
      feedback-channel:x:@.arguments/*/feedback-channel
   if
      eq:x:@signal/*/found
         .:bool:true
      .lambda
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:Site has robots.txt
               type:info
         sleep:100
         strings.concat
            .:"Found "
            get-count:x:@signal/*/sitemap/*
            .:" sitemaps in robots.txt file"
         unwrap:x:+/**
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:x:@strings.concat
               type:info
         sleep:100
         if
            exists:x:@signal/*/crawl-delay
            .lambda
               remove-nodes:x:@.arguments/*/delay
               unwrap:x:+/*
               validators.default:x:@.arguments
                  delay:x:@signal/*/crawl-delay
               strings.concat
                  .:"Robots.txt file contains a Crawl-Delay value of "
                  math.divide:x:@signal/*/crawl-delay
                     .:int:1000
                  .:" seconds"
               unwrap:x:+/**
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:x:@strings.concat
                     type:info
   else
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:Could not find a robots.txt file for website
            type:warning
      sleep:100
      strings.concat
         .:"We will try to retrieve sitemap from "
         get-value:x:@signal/*/sitemap/0
      unwrap:x:+/**
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:x:@strings.concat
            type:info
      sleep:100
   .filter-on-url:bool:false
   strings.split:x:@.arguments/*/url
      .:/
   if
      mt
         get-count:x:@strings.split/*
         .:int:2
      .lambda
         set-value:x:@.filter-on-url
            .:bool:true
   add:x:./*/signal/[1,2]
      get-nodes:x:@signal/*/sitemap
      get-nodes:x:@signal/*/allow
      get-nodes:x:@signal/*/disallow
   unwrap:x:+/*
   signal:magic.ai.load-sitemap
      max:x:@.arguments/*/max
      feedback-channel:x:@.arguments/*/feedback-channel
      url:x:@.arguments/*/url
      filter-on-url:x:@.filter-on-url
   strings.concat
      .:"Deleting old snippets for type '"
      get-value:x:@.arguments/*/type
      .:"' matching URL of "
      get-value:x:@.arguments/*/url
   unwrap:x:+/**
   sockets.signal:x:@.arguments/*/feedback-channel
      args
         message:x:@strings.concat
         type:info
   sleep:100
   .uri
   set-value:x:@.uri
      strings.concat
         get-value:x:@.arguments/*/url
         .:%
   data.connect:[generic|magic]
      data.execute:@"
delete from vss_ml_training_snippets
where rowid in (select id as rowid from ml_training_snippets where type = @type and uri like @uri);
delete from ml_training_snippets where type = @type and uri like @uri;"
         type:x:@.arguments/*/type
         uri:x:@.uri
   if
      eq:x:@signal/*/has-sitemap
         .:bool:true
      .lambda
         get-count:x:@signal/*/urls/*
         strings.concat
            .:"We found "
            get-value:x:@signal/*/total
            .:" URLs in sitemap(s), we will be scraping "
            get-value:x:@get-count
            .:" URLs"
         unwrap:x:+/**
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:x:@strings.concat
               type:info
         sleep:100
         if
            eq:x:@get-count
               .:int:0
            .lambda
               strings.concat
                  .:Warning, we could not find a single valid URL in site
               unwrap:x:+/**
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:x:@strings.concat
                     type:warning
               sleep:100
         else-if
            mt
               get-value:x:@signal/*/total
               get-value:x:@get-count
            .lambda
               strings.concat
                  .:"Warning, site contains more than "
                  get-value:x:@get-count
                  .:" URLs and will only be partially scraped"
               unwrap:x:+/**
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:x:@strings.concat
                     type:warning
               sleep:100
         if
            mt:x:@get-count
               .:int:0
            .lambda
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:------------------------------------------------------------------------------------------------------------------------
                     type:info
               sleep:100
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:"URLs we will scrape are as follows:"
                     type:info
               sleep:100
         for-each:x:@signal/*/urls/*
            unwrap:x:+/**
            sockets.signal:x:@.arguments/*/feedback-channel
               args
                  message:x:@.dp/#
                  type:info
            sleep:10
         for-each:x:@signal/*/urls/*
            try
               sockets.signal:x:@.arguments/*/feedback-channel
                  args
                     message:------------------------------------------------------------------------------------------------------------------------
                     type:info
               sleep:100
               unwrap:x:+/*
               signal:magic.ai.url.scrape
                  url:x:@.dp/#
                  type:x:@.arguments/*/type
                  threshold:x:@.arguments/*/threshold
                  summarize:x:@.arguments/*/summarize
                  feedback-channel:x:@.arguments/*/feedback-channel
                  images:x:@.arguments/*/images
                  lists:x:@.arguments/*/lists
                  code:x:@.arguments/*/code
                  insert_url:x:@.arguments/*/insert_url
               if
                  neq:x:@.dp/#
                     get-value:x:@signal/@signal/*/urls/0/-
                  .lambda
                     strings.concat
                        .:"Waiting for "
                        math.divide:x:@.arguments/*/delay
                           .:int:1000
                        .:" seconds to avoid exhausting web server"
                     unwrap:x:+/**
                     sockets.signal:x:@.arguments/*/feedback-channel
                        args
                           message:x:@strings.concat
                           type:info
                     sleep:100
                     sleep:x:@.arguments/*/delay
            .catch
               log.error:Could not scrape URL
                  url:x:@.dp/#
                  message:x:@.arguments/*/message
               strings.concat
                  .:"Could not scrape URL, error was: '"
                  get-value:x:@.arguments/*/message
                  .:"'"
               unwrap:x:+/**
               sockets.signal:x:@.arguments/@.arguments/*/feedback-channel
                  roles:root
                  args
                     message:x:@strings.concat
                     type:warning
               sleep:100
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:------------------------------------------------------------------------------------------------------------------------
               type:info
         sleep:100
         sockets.signal:magic.backend.message
            roles:root
            args
               message:Done creating OpenAI training data from URL
               type:success
         sleep:100
         log.info:OpenAI training data successfully created
            url:x:@.arguments/*/url
            type:x:@.arguments/*/type
         if
            exists:x:@.arguments/*/.onafter
            .lambda
               eval:x:@.arguments/*/.onafter
   else
      .urls
      .done
      unwrap:x:+/*/*
      add:x:@.urls
         .
            .:x:@.arguments/*/url
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:Could not find any valid sitemaps
            type:warning
      sleep:100
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:Trying to crawl site even though we did not find a valid sitemap
            type:info
      sleep:100
      while
         and
            exists:x:@.urls/*
            lt
               get-count:x:@.done/*
               get-value:x:@.arguments/*/max
         .lambda
            sockets.signal:x:@.arguments/*/feedback-channel
               args
                  message:------------------------------------------------------------------------------------------------------------------------
                  type:info
            sleep:100
            unwrap:x:+/*
            signal:magic.ai.url.scrape
               url:x:@.urls/0
               type:x:@.arguments/*/type
               images:bool:true
               code:bool:true
               lists:bool:true
               main:bool:true
               empty-completion:bool:false
               threshold:x:@.arguments/*/threshold
               summarize:x:@.arguments/*/summarize
               feedback-channel:x:@.arguments/*/feedback-channel
            add:x:@.done
               get-nodes:x:@.urls/0
            remove-nodes:x:@.urls/0
            for-each:x:@signal/*
               if
                  and
                     not-exists:x:"@.done/*/\"={@.dp/#}\""
                     not-exists:x:"@.urls/*/\"={@.dp/#}\""
                     strings.starts-with:x:@.dp/#
                        get-value:x:@.arguments/*/url
                  .lambda
                     add:x:@.urls
                        get-nodes:x:@.dp/#
            strings.concat
               .:"Waiting for "
               math.divide:x:@.arguments/*/delay
                  .:int:1000
               .:" seconds to avoid exhausting web server"
            unwrap:x:+/**
            sockets.signal:x:@.arguments/*/feedback-channel
               args
                  message:x:@strings.concat
                  type:info
            sleep:100
            sleep:x:@.arguments/*/delay
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:------------------------------------------------------------------------------------------------------------------------
            type:info
      sleep:100
      strings.concat
         .:"Done scraping "
         get-count:x:@.done/*
         .:" URLs"
      unwrap:x:+/**
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:x:@strings.concat
            type:info
      sleep:100
      log.info:OpenAI training data successfully created
         url:x:@.arguments/*/url
         type:x:@.arguments/*/type
      if
         exists:x:@.arguments/*/.onafter
         .lambda
            eval:x:@.arguments/*/.onafter
