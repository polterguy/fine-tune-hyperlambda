
/*
 * 1. The [http.post] slot initiates an HTTP POST request to the OpenAI embeddings API endpoint.
 * 2. The [headers] node customizes request headers by injecting an [Authorization] header whose value is dynamically sourced from the [.token] node, and explicitly sets [Content-Type] to "application/json".
 * 3. The [payload] node constructs the JSON body for the request, setting [input] to the value from [.arguments] → [prompt], and [model] to the value from [.arguments] → [vector_model].
 * 4. The [convert] node, set to true, ensures that the HTTP response is automatically parsed and returned as a Hyperlambda node structure instead of raw JSON.
 * 
 * Use cases:
 * - Submitting a user-supplied prompt to OpenAI to generate an embedding vector with a specified model.
 * - Integrating text embedding functionality into a Magic web API, using user authentication tokens.
 * - Building pipelines that require semantic vectorization of strings for downstream machine learning or search indexing.
 * - Automating the process of embedding content within a workflow, adapting to different OpenAI models by passing the model name dynamically.
 */
http.post:"https://api.openai.com/v1/embeddings"
   headers
      Authorization:x:@.token
      Content-Type:application/json
   payload
      input:x:@.arguments/*/prompt
      model:x:@.arguments/*/vector_model
   convert:true
