
// Parses a string (presumably a line from a robots.txt file), splits it by ":", trims and normalizes the key and value, then processes the directive based on its type (Crawl-Delay, User-Agent, Sitemap, Disallow, Allow). For Crawl-Delay, it validates and clamps the value, sending warnings if necessary. For User-Agent, it manages relevance and state for specific agents. For Sitemap, Disallow, and Allow, it constructs full URLs if needed and adds them to the appropriate collections, handling both absolute and relative paths.
if
   not
      strings.starts-with:x:@strings.trim
         .:#
   .lambda
      strings.split:x:@strings.trim
         .:":"
      if
         mte
            get-count:x:@strings.split/*
            .:int:2
         .lambda
            .value
            set-value:x:@.value
               strings.join:x:@strings.split/*/[1,100]
                  .:":"
            set-value:x:@strings.split/0
               strings.trim:x:@strings.split/0
                  .:@"
	 "
            set-value:x:@.value
               strings.trim:x:@.value
                  .:@"
	 "
            switch:x:@strings.split/0
               case:Crawl-Delay
               case:Crawl-delay
               case:crawl-delay
                  set-value:x:@.value
                     strings.replace-not-of:x:@.value
                        .:0123456789
                        .:
                  if
                     and
                        eq:x:@.relevant
                           .:bool:true
                        neq:x:@.value
                           .:
                     .lambda
                        try
                           set-value:x:@.crawl-delay
                              math.multiply
                                 .:int:1000
                                 convert:x:@.value
                                    type:int
                           if
                              mt:x:@.crawl-delay
                                 .:int:60000
                              .lambda
                                 sockets.signal:x:@.arguments/*/feedback-channel
                                    args
                                       message:Crawl-Delay was more than 60 seconds, using 60 seconds as our value
                                       type:warning
                                 set-value:x:@.crawl-delay
                                    .:int:60000
                        .catch
                           sockets.signal:x:@.arguments/*/feedback-channel
                              args
                                 message:Crawl-Delay was not a valid integer value, using 10 seconds as our value
                                 type:warning
                           set-value:x:@.crawl-delay
                              .:int:10000
               case:User-Agent
               case:User-agent
               case:user-agent
                  switch:x:@.value
                     case:*
                     case:AINIRO
                     case:GPTBot
                        if
                           eq:x:@.value
                              .:AINIRO
                           .lambda
                              remove-nodes:x:@.allow/*
                              remove-nodes:x:@.disallow/*
                              set-value:x:@.has-seen-ainiro
                                 .:bool:true
                              set-value:x:@.relevant
                                 .:bool:true
                        else
                           if
                              eq:x:@.has-seen-ainiro
                                 .:bool:false
                              .lambda
                                 set-value:x:@.relevant
                                    .:bool:true
                           else
                              set-value:x:@.relevant
                                 .:bool:false
                     default
                        set-value:x:@.relevant
                           .:bool:false
               case:Sitemap
               case:sitemap
                  if
                     or
                        strings.starts-with:x:@.value
                           .:"http://"
                        strings.starts-with:x:@.value
                           .:"https://"
                     .lambda
                        unwrap:x:+/*/*
                        add:x:@.sitemap
                           .
                              .:x:@.value
                  else
                     strings.concat
                        get-value:x:@.domain
                        .:/
                        get-value:x:@.value
                     strings.replace:x:@strings.concat
                        .://
                        .:/
                     unwrap:x:+/*/*
                     add:x:@.sitemap
                        .
                           .:x:@strings.replace
               case:Disallow
               case:disallow
                  if
                     eq:x:@.relevant
                        .:bool:true
                     .lambda
                        if
                           or
                              strings.starts-with:x:@.value
                                 .:"http://"
                              strings.starts-with:x:@.value
                                 .:"https://"
                           .lambda
                              unwrap:x:+/*/*
                              add:x:@.disallow
                                 .
                                    .:x:@.value
                        else
                           strings.concat
                              get-value:x:@.domain
                              get-value:x:@.value
                           unwrap:x:+/*/*
                           add:x:@.disallow
                              .
                                 .:x:@strings.concat
               case:Allow
               case:allow
                  if
                     eq:x:@.relevant
                        .:bool:true
                     .lambda
                        if
                           or
                              strings.starts-with:x:@.value
                                 .:"http://"
                              strings.starts-with:x:@.value
                                 .:"https://"
                           .lambda
                              unwrap:x:+/*/*
                              add:x:@.allow
                                 .
                                    .:x:@.value
                        else
                           strings.concat
                              get-value:x:@.domain
                              get-value:x:@.value
                           unwrap:x:+/*/*
                           add:x:@.allow
                              .
                                 .:x:@strings.concat
