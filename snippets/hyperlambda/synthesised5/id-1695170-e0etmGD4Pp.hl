
/*
 * 1. The [execute] slot is used to invoke the [magic.workflows.actions.execute] slot, which is responsible for running a workflow action.
 * 2. The [name] node specifies the name of the workflow action to execute, in this case "openai-query".
 * 3. The [filename] node points to the Hyperlambda file that implements the workflow action, located at [/modules/openai/workflows/actions/openai-query.hl].
 * 4. The [arguments] node provides parameters for the workflow action:
 *    - [model] sets the model to "gpt-4o".
 *    - [max_tokens] limits the response to 1500 tokens.
 *    - [instruction] retrieves its value dynamically from the [.system-message] node using the lambda expression `:x:@.system-message`.
 *    - [query] retrieves its value dynamically from the [.tmp] node using the lambda expression `:x:@.tmp`.
 * 
 * Use cases:
 * - Executing an OpenAI query with a specific model and token limit as part of a workflow.
 * - Dynamically passing instructions and query content to the workflow based on the current execution context.
 * - Integrating complex AI processing steps into a larger automated process within Magic workflows.
 */
execute:magic.workflows.actions.execute
   name:openai-query
   filename:/modules/openai/workflows/actions/openai-query.hl
   arguments
      model:gpt-4o
      max_tokens:int:1500
      instruction:x:@.system-message
      query:x:@.tmp
