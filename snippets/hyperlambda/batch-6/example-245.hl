
/*
 * This Hyperlambda endpoint processes training records from the 'hyperlambda' table of the 
 * 'fine-tune' database and dissects them into smaller, isolated training snippets — one per 
 * slot invocation (function-like call).
 *
 * Each snippet is contextually enriched via OpenAI and saved as a unique file for use in 
 * fine-tuning models. This method is known internally as the “Chop Suey” approach, breaking 
 * up full scripts into atomic examples.
 *
 * 1. [.arguments]
 *    - Accepts two required arguments:
 *      - [limit:long]   → Number of records to process.
 *      - [offset:long]  → Offset for pagination.
 *
 * 2. [.system-message]
 *    - Loads the OpenAI instruction from 'system-message-synthesiser.md' for comment generation.
 *
 * 3. [vocabulary]
 *    - Retrieves all slot names available in the system to validate what constitutes a real slot invocation.
 *
 * 4. [data.connect:fine-tune]
 *    - Connects to the fine-tune database to access training entries.
 *    - Filters for unsynthesized, non-static records and orders them by code complexity (prompt + code length).
 *
 * 5. [for-each:x:@data.select/*]
 *    - Loops through each Hyperlambda training record.
 *
 * 6. [hyper2lambda]
 *    - Converts the code field of each record to a lambda object for structured traversal.
 *
 * 7. [for-each:x:@hyper2lambda/**/*]
 *    - Recursively visits every node in the lambda tree structure.
 *
 * 8. [get-name + if exists in vocabulary]
 *    - Ensures the node is a valid slot invocation before processing.
 *
 * 9. [.tmp + add]
 *    - Creates a minimal lambda structure containing only the current node.
 *
 * 10. [lambda2hyper]
 *     - Converts the node to a raw Hyperlambda code snippet as string.
 *
 * 11. [log.info]
 *     - Logs the snippet being synthesized.
 *
 * 12. [execute:openai-context-from-database]
 *     - Retrieves contextual documentation from the 'magic-documentation' set, based on the current snippet.
 *
 * 13. [execute:openai-query]
 *     - Sends the snippet and retrieved context to OpenAI (using 'gpt-4o') to generate a relevant comment.
 *
 * 14. [unwrap + insert-before]
 *     - Adds the AI-generated comment to the beginning of the snippet as a file-level comment.
 *
 * 15. [lambda2hyper]
 *     - Re-serializes the annotated snippet back into Hyperlambda format with comments.
 *
 * 16. [.filename + io.file.save]
 *     - Constructs a unique filename using the original training ID and a 10-digit random suffix.
 *     - Saves the final result into the 'synthesised4' directory for downstream fine-tuning.
 *
 * This approach allows comprehensive coverage of your slot API surface, generating 
 * focused, context-rich examples that serve well in both supervised fine-tuning and 
 * retrieval-augmented workflows.
 */
.arguments
   limit:long
   offset:long
.type:public

// Ensuring both arguments are specified by caller!
validators.mandatory:x:@.arguments/*/limit
validators.mandatory:x:@.arguments/*/offset

log.info:Starting Chop Suey script
   limit:x:@.arguments/*/limit
   offset:x:@.arguments/*/offset

// Loading our system message file.
.system-message
set-value:x:@.system-message
   io.file.load:/modules/fine-tune-hyperlambda/system-message-synthesiser.md

vocabulary

// Connecting to our fine-tune database.
data.connect:fine-tune

   // Selecting records.
   data.select:"select * from hyperlambda where is_static = 0 and synthesised = 0 order by length(code) + length(prompt) desc limit @limit offset @offset"
      @limit:x:@.arguments/*/limit
      @offset:x:@.arguments/*/offset

   // Looping through each record returned from above.
   for-each:x:@data.select/*

      // Converting code to lambda.
      hyper2lambda:x:@.dp/#/*/code

      // Looping through all nodes in lambda object.
      for-each:x:@hyper2lambda/**/*

         // Verifying currently iterated node's name is a slot invocation.
         get-name:x:@.dp/#
         if
            exists:x:@vocabulary/*/={@get-name}
            .lambda

               // Creating a lambda object exclusively containing the currently iterated node.
               .tmp
               add:x:@.tmp
                  get-nodes:x:@.dp/#

               // Converting lambda object to Hyperlambda
               lambda2hyper:x:@.tmp/*

               // Logging
               log.info:Creating synthetic snippet
                  snippet:x:@lambda2hyper

               /*
                * Returns context for the specified [query] from the specified [type],
                * and returns to caller.
                *
                * Optionally add [threshold] and [max_tokens] to specify similarity and maximum
                * tokens to return. [type] is a machine learning type from your ml_types database table in
                * your magic database.
                */
               execute:magic.workflows.actions.execute
                  name:openai-context-from-database
                  filename:/modules/openai/workflows/actions/openai-context-from-database.hl
                  arguments
                     type:magic-documentation
                     query:x:@lambda2hyper
                     threshold:decimal:0.3
                     max_tokens:int:2000

               /*
                * Invokes OpenAI's chat API with the specified [model], [max_tokens], [context],
                * [instruction] and [query].
                *
                * Will use the default API key found from configurations.
                *
                * [context] is additional data you can supply to OpenAI such that it responds using
                * your data as its source for information. [instruction] is a system message allowing
                * you to change how OpenAI responds.
                */
               execute:magic.workflows.actions.execute
                  name:openai-query
                  filename:/modules/openai/workflows/actions/openai-query.hl
                  arguments
                     model:gpt-4o
                     max_tokens:int:1500
                     instruction:x:@.system-message
                     context:x:@execute/@execute/*/context
                     query:x:@lambda2hyper

               // Injecting comment into Hyperlambda.
               unwrap:x:+/*/*
               insert-before:x:@.tmp/0
                  .
                     ..:x:@execute/*/answer
               lambda2hyper:x:@.tmp/*
                  comments:true

               // Saving with a random filename in /synthesised4/ folder
               .filename
               set-value:x:@.filename
                  strings.concat
                     .:/modules/fine-tune-hyperlambda/snippets/hyperlambda/synthesised4/
                     .:id-
                     get-value:x:@for-each/@.dp/#/*/hyperlambda_id
                     .:-
                     crypto.random
                        min:10
                        max:10
                     .:.hl
               io.file.save:x:@.filename
                  get-value:x:@lambda2hyper
