
/*
 * Create a POST request to the OpenAI chat completions endpoint using [http.post], with the following configuration:
 * - Use [.token] as the Bearer token in the [Authorization] header.
 * - Set the [Content-Type] header to "application/json" and [Accept] header to "text/event-stream".
 * - Provide a [payload] using the "gpt-3.5-turbo" model, [max_tokens] set to 1000, and [temperature] set to 0.3.
 * - Construct the [messages] array with a "system" message whose content comes from [.arguments]/*/massagePrompt, and a "user" message whose content is taken from the currently iterated node's [completion] value.
 * - Set [convert] to true to automatically parse the response.
 */
http.post:"https://api.openai.com/v1/chat/completions"
   convert:bool:true
   headers
      Authorization:x:@.token
      Content-Type:application/json
      Accept:text/event-stream
   payload
      model:gpt-3.5-turbo
      max_tokens:int:1000
      temperature:decimal:0.3
      messages
         .
            role:system
            content:x:@.arguments/*/massagePrompt
         .
            role:user
            content:x:@.dp/#/*/completion
