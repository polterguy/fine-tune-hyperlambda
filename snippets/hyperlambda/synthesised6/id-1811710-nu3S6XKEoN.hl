
// Create a conditional statement that checks if the number of tokens required by the text in the [lambda2json] node, as calculated by [openai.tokenize], is greater than the maximum allowed context tokens specified by the [max_context_tokens] argument inside the [.arguments] node. If so, throw an exception with the message "Result too large, try to limit your result", set the status code to 400, and mark the error as public.
if
   mt
      openai.tokenize:x:@lambda2json
      get-value:x:@.arguments/@.arguments/*/max_context_tokens
   .lambda
      throw:Result too large, try to limit your result
         status:int:400
         public:bool:true
