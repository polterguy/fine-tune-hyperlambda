
// Create a conditional block that compares the number of tokens required by the text in the [lambda2json] node (using [openai.tokenize]) with the value of the [max_context_tokens] argument found at [@.arguments/*/max_context_tokens]. If the token count is greater than the allowed maximum, throw an exception with the message "Result too large, try to limit your result," set the status code to 400, and mark the error as public.
if
   mt
      openai.tokenize:x:@lambda2json
      get-value:x:@.arguments/@.arguments/*/max_context_tokens
   .lambda
      throw:Result too large, try to limit your result
         status:int:400
         public:bool:true
