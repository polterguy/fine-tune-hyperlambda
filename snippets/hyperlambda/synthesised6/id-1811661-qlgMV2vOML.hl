
/*
 * Create a Hyperlambda workflow that attempts to summarize a text snippet using the OpenAI chat completion API. The workflow should:
 * 
 * - First, unwrap all sibling nodes following the current node recursively using [.unwrap:x:+/**].
 * - Perform an HTTP POST request to "https://api.openai.com/v1/chat/completions" with the following:
 *   - Headers: [Authorization] from [.token] and [Content-Type] set to "application/json".
 *   - Payload: [model] from [.model], [max_tokens] from [.max-size], [temperature] set to 0.3, and [messages] consisting of a system message to create a summary and a user message with content from the current [.dp/#/*/completion].
 *   - Set [convert] to true to automatically parse the response.
 * - After the HTTP request, branch on the response code:
 *   - If the status code is 400, signal a warning message on the channel named in [.arguments/*/feedback-channel], sleep for 100ms, log the error details (including error message, status, and lambda representation of the response), and set [.no] to 0.
 *   - Else if the status code is between 200 (inclusive) and 300 (exclusive), signal an info message on the feedback channel, sleep for 100ms, set [.dp/#/*/completion] to the trimmed summary received from OpenAI, set [.dp/#/*/prompt] as "Summary; " concatenated with the first 150 characters of its previous value, and set [.no] to 0.
 *   - Else, signal a warning message on the feedback channel that a retry will occur, sleep for 3 seconds, log the error details as above, and decrement [.no] by 1.
 */
try
   unwrap:x:+/**
   http.post:"https://api.openai.com/v1/chat/completions"
      headers
         Authorization:x:@.token
         Content-Type:application/json
      payload
         model:x:@.model
         max_tokens:x:@.max-size
         temperature:decimal:0.3
         messages
            .
               role:system
               content:Create a summary of the following information
            .
               role:user
               content:x:@.dp/#/*/completion
      convert:true
   if
      eq:x:@http.post
         .:int:400
      .lambda
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:Could not summarize snippet, check your log for details
               type:warning
         sleep:100
         lambda2hyper:x:@http.post
         log.error:Something went wrong while invoking OpenAI
            message:x:@http.post/*/content/*/error/*/message
            status:x:@http.post
            error:x:@lambda2hyper
         set-value:x:@.no
            .:int:0
   else-if
      and
         mte:x:@http.post
            .:int:200
         lt:x:@http.post
            .:int:300
      .lambda
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:Successfully created summary of snippet
               type:info
         sleep:100
         set-value:x:@.dp/#/*/completion
            strings.trim:x:@http.post/*/content/*/choices/0/*/message/*/content
               .:@"
	 "
         set-value:x:@.dp/#/*/prompt
            strings.concat
               .:"Summary; "
               strings.substring:x:@.dp/#/*/prompt
                  .:int:0
                  .:int:150
         set-value:x:@.no
            .:int:0
   else
      sockets.signal:x:@.arguments/*/feedback-channel
         args
            message:Could not summarize snippet, check your log for details. Trying again in 3 seconds.
            type:warning
      sleep:3000
      lambda2hyper:x:@http.post
      log.error:Something went wrong while invoking OpenAI
         message:x:@http.post/*/content/*/error/*/message
         status:x:@http.post
         error:x:@lambda2hyper
      math.decrement:x:@.no
