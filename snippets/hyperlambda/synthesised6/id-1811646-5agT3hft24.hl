
// Create a Hyperlambda workflow that processes files if a [.handle] node is present. For each file, update the [.file-meta] node to append the filename, load the file's content into a [.content] node, and then conditionally generate a summary snippet using the OpenAI API if certain conditions are met (such as presence and validity of an argument [.massage], and the token count of [.content] being less than 15,000). If the summary is successfully created (API returns HTTP status 200â€“299), add a new snippet to the [.snippets] node with the prompt and completion. If not, or if the conditions are not met, add a fallback snippet. Finally, for every snippet in [.snippets], insert a new record into a [ml_training_snippets] table in a [generic|magic] data connection, storing type, prompt, completion, filename, and marking as not cached.
if:x:@.handle
   set-value:x:@.file-meta
      strings.concat
         get-value:x:@.file-meta
         .:" - Filename: "
         get-value:x:@.dp/#
   .content
   set-value:x:@.content
      io.file.load:x:@.dp/#
   .snippets
   if
      and
         exists:x:@.arguments/*/massage
         neq:x:@.arguments/*/massage
            .
         neq:x:@.arguments/*/massage
            .:
         lt
            openai.tokenize:x:@.content
            .:int:15000
      .lambda
         strings.concat
            .:"Creating summary for file: "
            get-value:x:@.dp/#
         unwrap:x:+/*/*/message
         sockets.signal:x:@.arguments/*/feedback-channel
            args
               message:x:@strings.concat
               type:info
         http.post:"https://api.openai.com/v1/chat/completions"
            headers
               Authorization:x:@.token
               Content-Type:application/json
            payload
               model:gpt-3.5-turbo-1106
               max_tokens:int:2000
               temperature:decimal:0.5
               messages
                  .
                     role:system
                     content:x:@.arguments/*/massage
                  .
                     role:system
                     content:x:@.content
            convert:true
         if
            and
               mte:x:@http.post
                  .:int:200
               lt:x:@http.post
                  .:int:300
            .lambda
               unwrap:x:+/*/*/*
               add:x:@.snippets
                  .
                     .
                        prompt:x:@http.post/*/content/*/choices/0/*/message/*/content
                        completion:x:@.content
         else
            strings.concat
               .:"Could not create summary for file: "
               get-value:x:@.dp/#
            unwrap:x:+/*/*/message
            sockets.signal:x:@.arguments/*/feedback-channel
               args
                  message:x:@strings.concat
                  type:warning
            unwrap:x:+/*/*/*
            add:x:@.snippets
               .
                  .
                     prompt:x:@.file-meta
                     completion:x:@.content
   else
      unwrap:x:+/*/*/*
      add:x:@.snippets
         .
            .
               prompt:x:@.file-meta
               completion:x:@.content
   data.connect:[generic|magic]
      for-each:x:@.snippets/*
         data.create
            table:ml_training_snippets
            values
               type:x:@.arguments/*/type
               prompt:x:@.dp/#/*/prompt
               completion:x:@.dp/#/*/completion
               filename:x:@.dp/@.dp/#
               cached:int:0
